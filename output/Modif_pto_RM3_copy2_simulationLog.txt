
WEC-Sim Read Input File ...   
Elapsed time is 0.155295 seconds.

WEC-Sim Pre-processing ...   
	Infinite water depth specified in BEM, "waves.waterDepth" set to 200m for vizualisation.
Elapsed time is 1533.231270 seconds.

WEC-Sim Simulation Settings:
	Start Time                     (sec) = 0
	End Time                       (sec) = 100000
	Time Step Size                 (sec) = 0.1
	Ramp Function Time             (sec) = 100
	Total Number of Time Steps           = 1000000 

Wave Environment: 
	Wave Type                            = Regular Waves (Constant Hydrodynamic Coefficients)
	Wave Height, H (m)                   = 2.5
	Wave Period, T (sec)                 = 8

List of Body: Number of Bodies = 2 

	***** Body Number 0, Name: float *****
	Body CG                          (m) = [0,0,-0.72]
	Body Mass                       (kg) = 725834 
	Body Diagonal MOI              (kgm2)= [2.09073E+07,2.13061E+07,3.70855E+07]

	***** Body Number 1, Name: spar *****
	Body CG                          (m) = [0,0,-21.29]
	Body Mass                       (kg) = 886691 
	Body Diagonal MOI              (kgm2)= [9.44196E+07,9.44071E+07,2.85422E+07]

List of PTO(s): Number of PTOs = 1 

	***** PTO Name: PTO1 *****
	PTO Stiffness           (N/m;Nm/rad) = 0
	PTO Damping           (Ns/m;Nsm/rad) = 0

List of Constraint(s): Number of Constraints = 1 

	***** Constraint Name: Constraint1 *****


Simulating the WEC device defined in the SimMechanics model Modif_pto_RM3_copy2.slx...   
[Warning: The block '<a href="matlab:open_and_hilite_hyperlink ('Modif_pto_RM3_copy2/Translational PTO Actuation Force/InternalMechanics/Data Store Read','error')">Modif_pto_RM3_copy2/Translational PTO Actuation Force/InternalMechanics/Data Store Read</a>' is reading from
the data store '<a href="matlab:open_and_hilite_hyperlink ('Modif_pto_RM3_copy2/Data Store Memory3','error')">Modif_pto_RM3_copy2/Data Store Memory3</a>' before any blocks have written to this entire region of memory at time
0.0. For performance reasons, occurrences of this diagnostic for this memory at other simulation time steps will be
suppressed.] 
[> In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('wecSim', '/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/wecSim.m', 251)" style="font-weight:bold">wecSim</a> (<a href="matlab: opentoline('/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/wecSim.m',251,0)">line 251</a>)
  In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('real_timeDQL', '/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/real_timeDQL.m', 159)" style="font-weight:bold">real_timeDQL</a> (<a href="matlab: opentoline('/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/real_timeDQL.m',159,0)">line 159</a>)] 
[Warning: The block '<a href="matlab:open_and_hilite_hyperlink ('Modif_pto_RM3_copy2/Translational PTO Actuation Force/InternalMechanics/Data Store Read1','error')">Modif_pto_RM3_copy2/Translational PTO Actuation Force/InternalMechanics/Data Store Read1</a>' is reading from
the data store '<a href="matlab:open_and_hilite_hyperlink ('Modif_pto_RM3_copy2/Data Store Memory14','error')">Modif_pto_RM3_copy2/Data Store Memory14</a>' before any blocks have written to this entire region of memory at
time 0.0. For performance reasons, occurrences of this diagnostic for this memory at other simulation time steps will be
suppressed.] 
[> In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('wecSim', '/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/wecSim.m', 251)" style="font-weight:bold">wecSim</a> (<a href="matlab: opentoline('/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/wecSim.m',251,0)">line 251</a>)
  In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('real_timeDQL', '/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/real_timeDQL.m', 159)" style="font-weight:bold">real_timeDQL</a> (<a href="matlab: opentoline('/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/real_timeDQL.m',159,0)">line 159</a>)] 
[Warning: The block '<a href="matlab:open_and_hilite_hyperlink ('Modif_pto_RM3_copy2/Q-NN Update','error')">Modif_pto_RM3_copy2/Q-NN Update</a>' is reading from element 1 of the data store '<a href="matlab:open_and_hilite_hyperlink ('Modif_pto_RM3_copy2/Data Store Memory8','error')">Modif_pto_RM3_copy2/Data
Store Memory8</a>' before any blocks have written to this memory at time 0.0. For performance reasons, occurrences of this
diagnostic for this memory at other simulation time steps will be suppressed.] 
[> In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('wecSim', '/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/wecSim.m', 251)" style="font-weight:bold">wecSim</a> (<a href="matlab: opentoline('/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/wecSim.m',251,0)">line 251</a>)
  In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('real_timeDQL', '/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/real_timeDQL.m', 159)" style="font-weight:bold">real_timeDQL</a> (<a href="matlab: opentoline('/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/real_timeDQL.m',159,0)">line 159</a>)] 
[Warning: The block '<a href="matlab:open_and_hilite_hyperlink ('Modif_pto_RM3_copy2/Q-NN Update','error')">Modif_pto_RM3_copy2/Q-NN Update</a>' is writing to element 1 of the data store '<a href="matlab:open_and_hilite_hyperlink ('Modif_pto_RM3_copy2/Data Store Memory8','error')">Modif_pto_RM3_copy2/Data Store
Memory8</a>' but the block '<a href="matlab:open_and_hilite_hyperlink ('Modif_pto_RM3_copy2/Q-NN Update','error')">Modif_pto_RM3_copy2/Q-NN Update</a>' has already read from this memory at time 0.0. For performance
reasons, occurrences of this diagnostic for this memory at other simulation time steps will be suppressed.] 
[> In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('wecSim', '/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/wecSim.m', 251)" style="font-weight:bold">wecSim</a> (<a href="matlab: opentoline('/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/wecSim.m',251,0)">line 251</a>)
  In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('real_timeDQL', '/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/real_timeDQL.m', 159)" style="font-weight:bold">real_timeDQL</a> (<a href="matlab: opentoline('/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/real_timeDQL.m',159,0)">line 159</a>)] 
[Warning: The block '<a href="matlab:open_and_hilite_hyperlink ('Modif_pto_RM3_copy2/Q-NN Update','error')">Modif_pto_RM3_copy2/Q-NN Update</a>' is reading from element 1 of the data store '<a href="matlab:open_and_hilite_hyperlink ('Modif_pto_RM3_copy2/Data Store Memory18','error')">Modif_pto_RM3_copy2/Data
Store Memory18</a>' before any blocks have written to this memory at time 0.0. For performance reasons, occurrences of this
diagnostic for this memory at other simulation time steps will be suppressed.] 
[> In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('wecSim', '/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/wecSim.m', 251)" style="font-weight:bold">wecSim</a> (<a href="matlab: opentoline('/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/wecSim.m',251,0)">line 251</a>)
  In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('real_timeDQL', '/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/real_timeDQL.m', 159)" style="font-weight:bold">real_timeDQL</a> (<a href="matlab: opentoline('/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/real_timeDQL.m',159,0)">line 159</a>)] 
[Warning: The block '<a href="matlab:open_and_hilite_hyperlink ('Modif_pto_RM3_copy2/Q-NN Update','error')">Modif_pto_RM3_copy2/Q-NN Update</a>' is reading from element 1 of the data store '<a href="matlab:open_and_hilite_hyperlink ('Modif_pto_RM3_copy2/Data Store Memory9','error')">Modif_pto_RM3_copy2/Data
Store Memory9</a>' before any blocks have written to this memory at time 0.0. For performance reasons, occurrences of this
diagnostic for this memory at other simulation time steps will be suppressed.] 
[> In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('wecSim', '/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/wecSim.m', 251)" style="font-weight:bold">wecSim</a> (<a href="matlab: opentoline('/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/wecSim.m',251,0)">line 251</a>)
  In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('real_timeDQL', '/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/real_timeDQL.m', 159)" style="font-weight:bold">real_timeDQL</a> (<a href="matlab: opentoline('/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/real_timeDQL.m',159,0)">line 159</a>)] 
[Warning: The block '<a href="matlab:open_and_hilite_hyperlink ('Modif_pto_RM3_copy2/Q-NN Update','error')">Modif_pto_RM3_copy2/Q-NN Update</a>' is reading from element 1 of the data store '<a href="matlab:open_and_hilite_hyperlink ('Modif_pto_RM3_copy2/Data Store Memory5','error')">Modif_pto_RM3_copy2/Data
Store Memory5</a>' before any blocks have written to this memory at time 0.0. For performance reasons, occurrences of this
diagnostic for this memory at other simulation time steps will be suppressed.] 
[> In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('wecSim', '/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/wecSim.m', 251)" style="font-weight:bold">wecSim</a> (<a href="matlab: opentoline('/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/wecSim.m',251,0)">line 251</a>)
  In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('real_timeDQL', '/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/real_timeDQL.m', 159)" style="font-weight:bold">real_timeDQL</a> (<a href="matlab: opentoline('/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/real_timeDQL.m',159,0)">line 159</a>)] 
MeanR =
     0
   NaN
   NaN
   NaN
   NaN
   NaN
   NaN
   NaN
   NaN
   NaN
   NaN
   NaN
   NaN
   NaN
   NaN
   NaN
   NaN
   NaN
   NaN
   NaN

current state : 1 next state : 1 taken action : 0  0
 next reward : NaN
iteration: 1
epsilon =
    0.9500

[Warning: The block '<a href="matlab:open_and_hilite_hyperlink ('Modif_pto_RM3_copy2/Action Selection','error')">Modif_pto_RM3_copy2/Action Selection</a>' is writing to element 1 of the data store '<a href="matlab:open_and_hilite_hyperlink ('Modif_pto_RM3_copy2/Data Store Memory14','error')">Modif_pto_RM3_copy2/Data
Store Memory14</a>' but the block '<a href="matlab:open_and_hilite_hyperlink ('Modif_pto_RM3_copy2/Translational PTO Actuation Force/InternalMechanics/Data Store Read1','error')">Modif_pto_RM3_copy2/Translational PTO Actuation Force/InternalMechanics/Data Store Read1</a>' has
already read from this memory at time 0.0. For performance reasons, occurrences of this diagnostic for this memory at other
simulation time steps will be suppressed.] 
[> In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('wecSim', '/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/wecSim.m', 251)" style="font-weight:bold">wecSim</a> (<a href="matlab: opentoline('/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/wecSim.m',251,0)">line 251</a>)
  In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('real_timeDQL', '/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/real_timeDQL.m', 159)" style="font-weight:bold">real_timeDQL</a> (<a href="matlab: opentoline('/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/real_timeDQL.m',159,0)">line 159</a>)] 
[Warning: The block '<a href="matlab:open_and_hilite_hyperlink ('Modif_pto_RM3_copy2/Action Selection','error')">Modif_pto_RM3_copy2/Action Selection</a>' is writing to element 1 of the data store '<a href="matlab:open_and_hilite_hyperlink ('Modif_pto_RM3_copy2/Data Store Memory3','error')">Modif_pto_RM3_copy2/Data
Store Memory3</a>' but the block '<a href="matlab:open_and_hilite_hyperlink ('Modif_pto_RM3_copy2/Translational PTO Actuation Force/InternalMechanics/Data Store Read','error')">Modif_pto_RM3_copy2/Translational PTO Actuation Force/InternalMechanics/Data Store Read</a>' has
already read from this memory at time 0.0. For performance reasons, occurrences of this diagnostic for this memory at other
simulation time steps will be suppressed.] 
[> In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('wecSim', '/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/wecSim.m', 251)" style="font-weight:bold">wecSim</a> (<a href="matlab: opentoline('/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/wecSim.m',251,0)">line 251</a>)
  In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('real_timeDQL', '/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/real_timeDQL.m', 159)" style="font-weight:bold">real_timeDQL</a> (<a href="matlab: opentoline('/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/real_timeDQL.m',159,0)">line 159</a>)] 
[Warning: The block '<a href="matlab:open_and_hilite_hyperlink ('Modif_pto_RM3_copy2/Action Selection','error')">Modif_pto_RM3_copy2/Action Selection</a>' is writing to element 1 of the data store '<a href="matlab:open_and_hilite_hyperlink ('Modif_pto_RM3_copy2/Data Store Memory9','error')">Modif_pto_RM3_copy2/Data
Store Memory9</a>' but the block '<a href="matlab:open_and_hilite_hyperlink ('Modif_pto_RM3_copy2/Q-NN Update','error')">Modif_pto_RM3_copy2/Q-NN Update</a>' has already read from this memory at time 0.0. For performance
reasons, occurrences of this diagnostic for this memory at other simulation time steps will be suppressed.] 
[> In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('wecSim', '/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/wecSim.m', 251)" style="font-weight:bold">wecSim</a> (<a href="matlab: opentoline('/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/wecSim.m',251,0)">line 251</a>)
  In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('real_timeDQL', '/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/real_timeDQL.m', 159)" style="font-weight:bold">real_timeDQL</a> (<a href="matlab: opentoline('/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/real_timeDQL.m',159,0)">line 159</a>)] 
MeanR =
   1.0e+04 *

         0
       NaN
       NaN
       NaN
       NaN
       NaN
       NaN
       NaN
       NaN
       NaN
       NaN
    1.7563
       NaN
       NaN
       NaN
       NaN
       NaN
       NaN
       NaN
       NaN

current state : 1 next state : 12 taken action : 5000000  5000000
 next reward : 1
iteration: 2
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
       NaN
       NaN
       NaN
       NaN
       NaN
       NaN
       NaN
       NaN
       NaN
       NaN
    1.7563
       NaN
       NaN
       NaN
       NaN
       NaN
       NaN
       NaN
    2.0016

current state : 12 next state : 20 taken action : 10000000   5000000
 next reward : 1
iteration: 3
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
       NaN
       NaN
       NaN
       NaN
       NaN
       NaN
       NaN
       NaN
       NaN
       NaN
    1.7563
       NaN
       NaN
       NaN
       NaN
       NaN
       NaN
       NaN
    2.0016

current state : 20 next state : 1 taken action : 0  0
 next reward : 0
iteration: 4
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
       NaN
       NaN
       NaN
    5.4151
       NaN
       NaN
       NaN
       NaN
       NaN
       NaN
    1.7563
       NaN
       NaN
       NaN
       NaN
       NaN
       NaN
       NaN
    2.0016

current state : 1 next state : 5 taken action : 2500000        0
 next reward : 1
iteration: 5
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
       NaN
       NaN
       NaN
    5.4151
       NaN
       NaN
       NaN
       NaN
       NaN
       NaN
    1.7563
       NaN
       NaN
       NaN
    1.6586
       NaN
       NaN
       NaN
    2.0016

current state : 5 next state : 16 taken action : 7500000  5000000
 next reward : 0.002696
[Warning: The block '<a href="matlab:open_and_hilite_hyperlink ('Modif_pto_RM3_copy2/Q-NN Update','error')">Modif_pto_RM3_copy2/Q-NN Update</a>' is reading from element 16 of the data store '<a href="matlab:open_and_hilite_hyperlink ('Modif_pto_RM3_copy2/Data Store Memory7','error')">Modif_pto_RM3_copy2/Data
Store Memory7</a>' before any blocks have written to this memory at time 800.0. For performance reasons, occurrences of this
diagnostic for this memory at other simulation time steps will be suppressed.] 
[> In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('wecSim', '/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/wecSim.m', 251)" style="font-weight:bold">wecSim</a> (<a href="matlab: opentoline('/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/wecSim.m',251,0)">line 251</a>)
  In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('real_timeDQL', '/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/real_timeDQL.m', 159)" style="font-weight:bold">real_timeDQL</a> (<a href="matlab: opentoline('/Users/ghleila/Downloads/WaveEnergyConversion/wec2/wec/real_timeDQL.m',159,0)">line 159</a>)] 
iteration: 6
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
       NaN
       NaN
       NaN
    5.4151
       NaN
       NaN
       NaN
    0.6308
       NaN
       NaN
    1.7563
       NaN
       NaN
       NaN
    1.6586
       NaN
       NaN
       NaN
    2.0016

current state : 16 next state : 9 taken action : 5000000        0
 next reward : 2.1455e-05
iteration: 7
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
       NaN
   -0.0313
       NaN
    5.4151
       NaN
       NaN
       NaN
    0.6308
       NaN
       NaN
    1.7563
       NaN
       NaN
       NaN
    1.6586
       NaN
       NaN
       NaN
    2.0016

current state : 9 next state : 3 taken action : 0  2500000
 next reward : -6.4303e-12
iteration: 8
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
       NaN
   -0.0313
   -0.0008
    5.4151
       NaN
       NaN
       NaN
    0.6308
       NaN
       NaN
    1.7563
       NaN
       NaN
       NaN
    1.6586
       NaN
       NaN
       NaN
    2.0016

current state : 3 next state : 4 taken action : 0  5000000
 next reward : -6.3319e-20
iteration: 9
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
       NaN
   -0.0313
   -0.0008
    5.4151
       NaN
       NaN
       NaN
    0.6308
       NaN
       NaN
    1.1072
       NaN
       NaN
       NaN
    1.6586
       NaN
       NaN
       NaN
    2.0016

current state : 4 next state : 12 taken action : 5000000  5000000
 next reward : 0.00035738
iteration: 10
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
       NaN
   -0.0313
   -0.0008
    5.4151
       NaN
       NaN
       NaN
    0.6308
       NaN
       NaN
    1.1072
       NaN
       NaN
       NaN
    1.6586
       NaN
       NaN
       NaN
    1.2198

current state : 12 next state : 20 taken action : 10000000   5000000
 next reward : 0.00058005
iteration: 11
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
       NaN
   -0.0313
   -0.0008
    5.4151
       NaN
       NaN
       NaN
    0.6308
       NaN
       NaN
    1.1072
       NaN
       NaN
       NaN
    1.6586
       NaN
    0.4875
       NaN
    1.2198

current state : 20 next state : 18 taken action : 10000000   1000000
 next reward : 5.9106e-06
iteration: 12
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
       NaN
   -0.0313
   -0.0008
    5.4151
       NaN
       NaN
       NaN
    0.6308
       NaN
       NaN
    1.1072
       NaN
       NaN
       NaN
    1.0601
       NaN
    0.4875
       NaN
    1.2198

current state : 18 next state : 16 taken action : 7500000  5000000
 next reward : 0.00028759
iteration: 13
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0313
   -0.0008
    5.4151
       NaN
       NaN
       NaN
    0.6308
       NaN
       NaN
    1.1072
       NaN
       NaN
       NaN
    1.0601
       NaN
    0.4875
       NaN
    1.2198

current state : 16 next state : 2 taken action : 0  1000000
 next reward : 1.1889e-11
iteration: 14
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0295
   -0.0008
    5.4151
       NaN
       NaN
       NaN
    0.6308
       NaN
       NaN
    1.1072
       NaN
       NaN
       NaN
    1.0601
       NaN
    0.4875
       NaN
    1.2198

current state : 2 next state : 3 taken action : 0  2500000
 next reward : -4.834e-12
iteration: 15
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0295
   -0.0008
    5.4151
       NaN
       NaN
       NaN
    0.6308
       NaN
       NaN
    1.1072
       NaN
       NaN
       NaN
    1.0601
       NaN
    0.4875
       NaN
    1.2198

current state : 3 next state : 1 taken action : 0  0
 next reward : 0
iteration: 16
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0295
   -0.0008
    5.4151
       NaN
       NaN
       NaN
    0.6308
       NaN
       NaN
    1.1072
    0.3784
       NaN
       NaN
    1.0601
       NaN
    0.4875
       NaN
    1.2198

current state : 1 next state : 13 taken action : 7500000        0
 next reward : 1.666e-06
iteration: 17
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0295
   -0.0008
    5.4151
       NaN
       NaN
       NaN
    0.6308
       NaN
       NaN
    1.1072
    0.3784
       NaN
       NaN
    1.0601
       NaN
    0.4875
    0.5176
    1.2198

current state : 13 next state : 19 taken action : 10000000   2500000
 next reward : 7.9816e-06
iteration: 18
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0295
   -0.0008
    5.4151
       NaN
       NaN
       NaN
    0.6308
       NaN
       NaN
    1.1072
    0.3784
       NaN
       NaN
    0.8612
       NaN
    0.4875
    0.5176
    1.2198

current state : 19 next state : 16 taken action : 7500000  5000000
 next reward : 0.00010174
iteration: 19
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0295
   -0.0008
    5.4151
       NaN
    0.8492
       NaN
    0.6308
       NaN
       NaN
    1.1072
    0.3784
       NaN
       NaN
    0.8612
       NaN
    0.4875
    0.5176
    1.2198

current state : 16 next state : 7 taken action : 2500000  2500000
 next reward : 9.485e-05
iteration: 20
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0295
   -0.0008
    5.4151
       NaN
    0.8492
       NaN
    0.6308
       NaN
       NaN
    1.1072
    0.3784
       NaN
       NaN
    0.8612
       NaN
    0.4875
    0.5176
    1.2198

current state : 7 next state : 1 taken action : 0  0
 next reward : 0
iteration: 21
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0295
   -0.0008
    5.4151
       NaN
    1.4636
       NaN
    0.6308
       NaN
       NaN
    1.1072
    0.3784
       NaN
       NaN
    0.8612
       NaN
    0.4875
    0.5176
    1.2198

current state : 1 next state : 7 taken action : 2500000  2500000
 next reward : 0.0014424
iteration: 22
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0295
   -0.0008
    5.4151
       NaN
    1.4636
       NaN
    0.6187
       NaN
       NaN
    1.1072
    0.3784
       NaN
       NaN
    0.8612
       NaN
    0.4875
    0.5176
    1.2198

current state : 7 next state : 9 taken action : 5000000        0
 next reward : 1.9473e-05
iteration: 23
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0295
   -0.0008
    5.4151
       NaN
    1.4636
       NaN
    0.6187
       NaN
       NaN
    1.1072
    0.3784
       NaN
       NaN
    0.8612
       NaN
    0.4870
    0.5176
    1.2198

current state : 9 next state : 18 taken action : 10000000   1000000
 next reward : 5.8826e-06
iteration: 24
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0295
   -0.0008
    5.4151
       NaN
    1.4636
       NaN
    0.6187
       NaN
       NaN
    1.1072
    0.3784
       NaN
    0.6427
    0.8612
       NaN
    0.4870
    0.5176
    1.2198

current state : 18 next state : 15 taken action : 7500000  2500000
 next reward : 2.3554e-05
iteration: 25
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0295
   -0.0008
    5.4151
       NaN
    1.4636
       NaN
    0.6187
       NaN
       NaN
    1.1072
    0.3784
    0.6313
    0.6427
    0.8612
       NaN
    0.4870
    0.5176
    1.2198

current state : 15 next state : 14 taken action : 7500000  1000000
 next reward : 2.1528e-05
iteration: 26
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0254
   -0.0008
    5.4151
       NaN
    1.4636
       NaN
    0.6187
       NaN
       NaN
    1.1072
    0.3784
    0.6313
    0.6427
    0.8612
       NaN
    0.4870
    0.5176
    1.2198

current state : 14 next state : 3 taken action : 0  2500000
 next reward : -2.2895e-12
iteration: 27
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0254
   -0.0008
    5.4151
       NaN
    1.4636
       NaN
    0.6187
       NaN
       NaN
    1.1072
    0.3784
    0.6313
    0.6427
    0.8612
       NaN
    0.4909
    0.5176
    1.2198

current state : 3 next state : 18 taken action : 10000000   1000000
 next reward : 6.1205e-06
iteration: 28
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0254
   -0.0008
    5.4151
       NaN
    1.4636
       NaN
    0.6187
       NaN
       NaN
    1.1072
    0.3784
    0.6313
    0.6427
    0.8612
       NaN
    0.4897
    0.5176
    1.2198

current state : 18 next state : 18 taken action : 10000000   1000000
 next reward : 6.0456e-06
iteration: 29
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0254
   -0.0008
    5.4151
       NaN
    1.4636
    0.3080
    0.6187
       NaN
       NaN
    1.1072
    0.3784
    0.6313
    0.6427
    0.8612
       NaN
    0.4897
    0.5176
    1.2198

current state : 18 next state : 8 taken action : 2500000  5000000
 next reward : 5.9483e-07
iteration: 30
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0254
   -0.0008
    3.2192
       NaN
    1.4636
    0.3080
    0.6187
       NaN
       NaN
    1.1072
    0.3784
    0.6313
    0.6427
    0.8612
       NaN
    0.4897
    0.5176
    1.2198

current state : 8 next state : 5 taken action : 2500000        0
 next reward : 1
iteration: 31
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0254
   -0.0008
    3.2192
       NaN
    1.4636
    0.3080
    0.6187
       NaN
       NaN
    1.1072
    0.4367
    0.6313
    0.6427
    0.8612
       NaN
    0.4897
    0.5176
    1.2198

current state : 5 next state : 13 taken action : 7500000        0
 next reward : 4.5935e-05
iteration: 32
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0254
   -0.0008
    3.2192
       NaN
    1.4636
    0.3080
    0.6187
       NaN
       NaN
    1.1072
    0.4367
    0.6313
    0.6427
    0.8612
       NaN
    0.4897
    0.5162
    1.2198

current state : 13 next state : 19 taken action : 10000000   2500000
 next reward : 0.00010597
iteration: 33
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0254
   -0.0008
    3.2192
       NaN
    1.4636
    0.3080
    0.6272
       NaN
       NaN
    1.1072
    0.4367
    0.6313
    0.6427
    0.8612
       NaN
    0.4897
    0.5162
    1.2198

current state : 19 next state : 9 taken action : 5000000        0
 next reward : 0.00028083
iteration: 34
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0270
   -0.0008
    3.2192
       NaN
    1.4636
    0.3080
    0.6272
       NaN
       NaN
    1.1072
    0.4367
    0.6313
    0.6427
    0.8612
       NaN
    0.4897
    0.5162
    1.2198

current state : 9 next state : 3 taken action : 0  2500000
 next reward : -4.1329e-11
iteration: 35
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0270
   -0.0008
    3.2192
       NaN
    1.4636
    0.3080
    0.6327
       NaN
       NaN
    1.1072
    0.4367
    0.6313
    0.6427
    0.8612
       NaN
    0.4897
    0.5162
    1.2198

current state : 3 next state : 9 taken action : 5000000        0
 next reward : 0.00029326
iteration: 36
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0270
   -0.0008
    3.2192
       NaN
    1.4636
    0.3080
    0.6327
       NaN
       NaN
    1.1072
    0.4367
    0.6313
    0.6427
    0.7604
       NaN
    0.4897
    0.5162
    1.2198

current state : 9 next state : 16 taken action : 7500000  5000000
 next reward : 0.00073528
iteration: 37
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0248
   -0.0008
    3.2192
       NaN
    1.4636
    0.3080
    0.6327
       NaN
       NaN
    1.1072
    0.4367
    0.6313
    0.6427
    0.7604
       NaN
    0.4897
    0.5162
    1.2198

current state : 16 next state : 3 taken action : 0  2500000
 next reward : -2.6929e-11
iteration: 38
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0248
   -0.0008
    3.2192
    1.4105
    1.4636
    0.3080
    0.6327
       NaN
       NaN
    1.1072
    0.4367
    0.6313
    0.6427
    0.7604
       NaN
    0.4897
    0.5162
    1.2198

current state : 3 next state : 6 taken action : 2500000  1000000
 next reward : 0.016151
iteration: 39
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0248
   -0.0008
    3.2192
    1.4105
    1.4636
    0.3080
    0.6327
       NaN
       NaN
    1.1072
    0.4385
    0.6313
    0.6427
    0.7604
       NaN
    0.4897
    0.5162
    1.2198

current state : 6 next state : 13 taken action : 7500000        0
 next reward : 4.6874e-05
iteration: 40
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0248
   -0.0008
    3.2192
    1.4105
    1.4636
    0.3080
    0.6327
       NaN
       NaN
    1.1072
    0.4385
    0.6313
    0.6427
    0.6993
       NaN
    0.4897
    0.5162
    1.2198

current state : 13 next state : 16 taken action : 7500000  5000000
 next reward : 0.00048375
iteration: 41
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0248
   -0.0008
    3.2192
    1.4105
    1.4636
    0.3080
    0.6327
       NaN
       NaN
    1.1072
    0.4385
    0.6313
    0.6427
    0.6604
       NaN
    0.4897
    0.5162
    1.2198

current state : 16 next state : 16 taken action : 7500000  5000000
 next reward : 0.00036325
iteration: 42
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0248
   -0.0008
    3.2192
    1.4105
    1.4636
    0.3080
    0.6327
       NaN
       NaN
    1.1072
    0.4385
    0.6313
    0.6448
    0.6604
       NaN
    0.4897
    0.5162
    1.2198

current state : 16 next state : 15 taken action : 7500000  2500000
 next reward : 0.00032237
iteration: 43
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0248
   -0.0008
    3.2192
    1.4105
    1.4636
    0.3080
    0.6327
       NaN
       NaN
    1.1072
    0.4385
    0.6313
    0.6448
    0.6604
       NaN
    0.4897
    0.5204
    1.2198

current state : 15 next state : 19 taken action : 10000000   2500000
 next reward : 0.00011043
iteration: 44
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0354
   -0.0248
   -0.0008
    3.2192
    1.4105
    1.4636
    0.3080
    0.6327
       NaN
       NaN
    0.8871
    0.4385
    0.6313
    0.6448
    0.6604
       NaN
    0.4897
    0.5204
    1.2198

current state : 19 next state : 12 taken action : 5000000  5000000
 next reward : 0.0015893
iteration: 45
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0248
   -0.0008
    3.2192
    1.4105
    1.4636
    0.3080
    0.6327
       NaN
       NaN
    0.8871
    0.4385
    0.6313
    0.6448
    0.6604
       NaN
    0.4897
    0.5204
    1.2198

current state : 12 next state : 2 taken action : 0  1000000
 next reward : 1.9241e-10
iteration: 46
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0248
   -0.0008
    3.2192
    1.4105
    1.4636
    0.3080
    0.6327
    0.7757
       NaN
    0.8871
    0.4385
    0.6313
    0.6448
    0.6604
       NaN
    0.4897
    0.5204
    1.2198

current state : 2 next state : 10 taken action : 5000000  1000000
 next reward : 0.0008126
iteration: 47
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0248
   -0.0008
    3.2192
    1.4105
    1.4636
    0.3080
    0.6327
    0.7757
       NaN
    0.8871
    0.4385
    0.6313
    0.6448
    0.6604
       NaN
    0.4897
    0.5204
    0.9577

current state : 10 next state : 20 taken action : 10000000   5000000
 next reward : 0.0023304
iteration: 48
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0248
   -0.0008
    3.2192
    1.4105
    1.4636
    0.3080
    0.6327
    0.7757
       NaN
    0.8871
    0.4385
    0.6313
    0.6448
    0.6604
    0.3195
    0.4897
    0.5204
    0.9577

current state : 20 next state : 17 taken action : 10000000         0
 next reward : 9.6282e-06
iteration: 49
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0248
   -0.0008
    3.2192
    1.4105
    1.2807
    0.3080
    0.6327
    0.7757
       NaN
    0.8871
    0.4385
    0.6313
    0.6448
    0.6604
    0.3195
    0.4897
    0.5204
    0.9577

current state : 17 next state : 7 taken action : 2500000  2500000
 next reward : 0.0099655
iteration: 50
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0248
   -0.0008
    3.2192
    1.4105
    1.2807
    0.3080
    0.6327
    0.7757
    0.7983
    0.8871
    0.4385
    0.6313
    0.6448
    0.6604
    0.3195
    0.4897
    0.5204
    0.9577

current state : 7 next state : 11 taken action : 5000000  2500000
 next reward : 0.00093782
iteration: 51
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0231
   -0.0008
    3.2192
    1.4105
    1.2807
    0.3080
    0.6327
    0.7757
    0.7983
    0.8871
    0.4385
    0.6313
    0.6448
    0.6604
    0.3195
    0.4897
    0.5204
    0.9577

current state : 11 next state : 3 taken action : 0  2500000
 next reward : -1.903e-11
iteration: 52
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0231
   -0.0008
    3.2192
    1.4105
    1.2807
    0.3080
    0.6327
    0.7757
    0.7983
    0.8871
    0.4385
    0.6313
    0.6448
    0.6604
    0.3260
    0.4897
    0.5204
    0.9577

current state : 3 next state : 17 taken action : 10000000         0
 next reward : 1.0647e-05
iteration: 53
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0231
   -0.0008
    3.2192
    1.4105
    1.2807
    0.3080
    0.6327
    0.7757
    0.7983
    0.8871
    0.4385
    0.6313
    0.6448
    0.6604
    0.3260
    0.4897
    0.5204
    0.9577

current state : 17 next state : 1 taken action : 0  0
 next reward : 0
iteration: 54
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0231
   -0.0008
    3.2192
    1.4105
    1.2807
    0.3080
    0.6327
    0.7757
    0.7983
    0.8871
    0.4385
    0.6313
    0.6448
    0.6604
    0.3077
    0.4897
    0.5204
    0.9577

current state : 1 next state : 17 taken action : 10000000         0
 next reward : 7.9733e-06
iteration: 55
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0231
   -0.0008
    3.2192
    1.4105
    1.2807
    0.3080
    0.6413
    0.7757
    0.7983
    0.8871
    0.4385
    0.6313
    0.6448
    0.6604
    0.3077
    0.4897
    0.5204
    0.9577

current state : 17 next state : 9 taken action : 5000000        0
 next reward : 0.00031377
iteration: 56
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0231
   -0.0008
    3.2192
    1.4649
    1.2807
    0.3080
    0.6413
    0.7757
    0.7983
    0.8871
    0.4385
    0.6313
    0.6448
    0.6604
    0.3077
    0.4897
    0.5204
    0.9577

current state : 9 next state : 6 taken action : 2500000  1000000
 next reward : 0.019511
iteration: 57
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0226
   -0.0008
    3.2192
    1.4649
    1.2807
    0.3080
    0.6413
    0.7757
    0.7983
    0.8871
    0.4385
    0.6313
    0.6448
    0.6604
    0.3077
    0.4897
    0.5204
    0.9577

current state : 6 next state : 3 taken action : 0  2500000
 next reward : -1.6977e-11
iteration: 58
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0226
   -0.0008
    3.2192
    1.4649
    1.2807
    0.3080
    0.6413
    0.7757
    0.7983
    0.8871
    0.4385
    0.6377
    0.6448
    0.6604
    0.3077
    0.4897
    0.5204
    0.9577

current state : 3 next state : 14 taken action : 7500000  1000000
 next reward : 0.00030514
iteration: 59
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0219
   -0.0008
    3.2192
    1.4649
    1.2807
    0.3080
    0.6413
    0.7757
    0.7983
    0.8871
    0.4385
    0.6377
    0.6448
    0.6604
    0.3077
    0.4897
    0.5204
    0.9577

current state : 14 next state : 3 taken action : 0  2500000
 next reward : -1.4603e-11
iteration: 60
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0219
   -0.0008
    3.2192
    1.4649
    1.2807
    0.3080
    0.6426
    0.7757
    0.7983
    0.8871
    0.4385
    0.6377
    0.6448
    0.6604
    0.3077
    0.4897
    0.5204
    0.9577

current state : 3 next state : 9 taken action : 5000000        0
 next reward : 0.00031705
iteration: 61
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0219
   -0.0008
    3.2192
    1.4649
    1.2807
    0.3080
    0.6426
    0.7757
    0.7983
    0.8871
    0.4385
    0.6377
    0.6448
    0.6604
    0.3077
    0.4890
    0.5204
    0.9577

current state : 9 next state : 18 taken action : 10000000   1000000
 next reward : 8.0848e-05
iteration: 62
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0219
   -0.0008
    3.2192
    1.4649
    1.2807
    0.3080
    0.6426
    0.8353
    0.7983
    0.8871
    0.4385
    0.6377
    0.6448
    0.6604
    0.3077
    0.4890
    0.5204
    0.9577

current state : 18 next state : 10 taken action : 5000000  1000000
 next reward : 0.0011765
iteration: 63
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0219
   -0.0008
    3.2192
    1.4649
    1.2807
    0.3080
    0.6429
    0.8353
    0.7983
    0.8871
    0.4385
    0.6377
    0.6448
    0.6604
    0.3077
    0.4890
    0.5204
    0.9577

current state : 10 next state : 9 taken action : 5000000        0
 next reward : 0.0003177
iteration: 64
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0219
   -0.0008
    3.2192
    1.4823
    1.2807
    0.3080
    0.6429
    0.8353
    0.7983
    0.8871
    0.4385
    0.6377
    0.6448
    0.6604
    0.3077
    0.4890
    0.5204
    0.9577

current state : 9 next state : 6 taken action : 2500000  1000000
 next reward : 0.020698
iteration: 65
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0219
   -0.0008
    3.2192
    1.4823
    1.2807
    0.3080
    0.6429
    0.8353
    0.7983
    0.7781
    0.4385
    0.6377
    0.6448
    0.6604
    0.3077
    0.4890
    0.5204
    0.9577

current state : 6 next state : 12 taken action : 5000000  5000000
 next reward : 0.00082476
iteration: 66
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0219
   -0.0008
    2.4873
    1.4823
    1.2807
    0.3080
    0.6429
    0.8353
    0.7983
    0.7781
    0.4385
    0.6377
    0.6448
    0.6604
    0.3077
    0.4890
    0.5204
    0.9577

current state : 12 next state : 5 taken action : 2500000        0
 next reward : 1
iteration: 67
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0219
   -0.0008
    2.4873
    1.4823
    1.2807
    0.3080
    0.6429
    0.8353
    0.7983
    0.7781
    0.4385
    0.6377
    0.6448
    0.6604
    0.3077
    0.4893
    0.5204
    0.9577

current state : 5 next state : 18 taken action : 10000000   1000000
 next reward : 0.00029471
iteration: 68
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0219
   -0.0008
    2.4873
    1.4823
    1.2807
    0.3080
    0.6429
    0.8353
    0.7983
    0.7781
    0.4385
    0.6377
    0.6441
    0.6604
    0.3077
    0.4893
    0.5204
    0.9577

current state : 18 next state : 15 taken action : 7500000  2500000
 next reward : 0.0011649
iteration: 69
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0219
   -0.0008
    2.4873
    1.4823
    1.2807
    0.3080
    0.6429
    0.8542
    0.7983
    0.7781
    0.4385
    0.6377
    0.6441
    0.6604
    0.3077
    0.4893
    0.5204
    0.9577

current state : 15 next state : 10 taken action : 5000000  1000000
 next reward : 0.0047768
iteration: 70
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0219
   -0.0008
    2.4873
    1.4823
    1.2807
    0.3080
    0.6429
    0.8542
    0.7983
    0.7781
    0.4385
    0.6377
    0.6441
    0.6324
    0.3077
    0.4893
    0.5204
    0.9577

current state : 10 next state : 16 taken action : 7500000  5000000
 next reward : 0.0010625
iteration: 71
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0219
   -0.0008
    2.4873
    1.4823
    1.2807
    0.3080
    0.6429
    0.8542
    0.7983
    0.7781
    0.4385
    0.6359
    0.6441
    0.6324
    0.3077
    0.4893
    0.5204
    0.9577

current state : 16 next state : 14 taken action : 7500000  1000000
 next reward : 0.0010925
iteration: 72
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0219
   -0.0008
    2.4873
    1.4823
    1.2807
    0.3080
    0.6429
    0.8640
    0.7983
    0.7781
    0.4385
    0.6359
    0.6441
    0.6324
    0.3077
    0.4893
    0.5204
    0.9577

current state : 14 next state : 10 taken action : 5000000  1000000
 next reward : 0.0050562
iteration: 73
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0219
   -0.0008
    2.4873
    1.4823
    1.1718
    0.3080
    0.6429
    0.8640
    0.7983
    0.7781
    0.4385
    0.6359
    0.6441
    0.6324
    0.3077
    0.4893
    0.5204
    0.9577

current state : 10 next state : 7 taken action : 2500000  2500000
 next reward : 0.023205
iteration: 74
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0219
   -0.0008
    2.4873
    1.4823
    1.1718
    0.3080
    0.6429
    0.8640
    0.7975
    0.7781
    0.4385
    0.6359
    0.6441
    0.6324
    0.3077
    0.4893
    0.5204
    0.9577

current state : 7 next state : 11 taken action : 5000000  2500000
 next reward : 0.0033877
iteration: 75
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0219
   -0.0008
    2.4873
    1.4823
    1.1718
    0.3080
    0.6429
    0.8640
    0.7975
    0.7781
    0.4385
    0.6359
    0.6441
    0.6324
    0.3077
    0.4893
    0.5204
    0.8278

current state : 11 next state : 20 taken action : 10000000   5000000
 next reward : 0.0040841
iteration: 76
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0219
   -0.0017
    2.4873
    1.4823
    1.1718
    0.3080
    0.6429
    0.8640
    0.7975
    0.7781
    0.4385
    0.6359
    0.6441
    0.6324
    0.3077
    0.4893
    0.5204
    0.8278

current state : 20 next state : 4 taken action : 0  5000000
 next reward : -1.6608e-16
iteration: 77
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0219
   -0.0017
    2.1212
    1.4823
    1.1718
    0.3080
    0.6429
    0.8640
    0.7975
    0.7781
    0.4385
    0.6359
    0.6441
    0.6324
    0.3077
    0.4893
    0.5204
    0.8278

current state : 4 next state : 5 taken action : 2500000        0
 next reward : 1
iteration: 78
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0219
   -0.0017
    2.1212
    1.4823
    1.1718
    0.3080
    0.6429
    0.8640
    0.7975
    0.7781
    0.4385
    0.6359
    0.6441
    0.6117
    0.3077
    0.4893
    0.5204
    0.8278

current state : 5 next state : 16 taken action : 7500000  5000000
 next reward : 0.0019935
iteration: 79
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0219
   -0.0017
    2.1212
    1.4823
    1.1718
    0.3093
    0.6429
    0.8640
    0.7975
    0.7781
    0.4385
    0.6359
    0.6441
    0.6117
    0.3077
    0.4893
    0.5204
    0.8278

current state : 16 next state : 8 taken action : 2500000  5000000
 next reward : 6.5961e-05
iteration: 80
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0219
   -0.0017
    1.9016
    1.4823
    1.1718
    0.3093
    0.6429
    0.8640
    0.7975
    0.7781
    0.4385
    0.6359
    0.6441
    0.6117
    0.3077
    0.4893
    0.5204
    0.8278

current state : 8 next state : 5 taken action : 2500000        0
 next reward : 1
iteration: 81
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0219
   -0.0017
    1.7546
    1.4823
    1.1718
    0.3093
    0.6429
    0.8640
    0.7975
    0.7781
    0.4385
    0.6359
    0.6441
    0.6117
    0.3077
    0.4893
    0.5204
    0.8278

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 1
iteration: 82
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0367
   -0.0219
   -0.0017
    1.7546
    1.4823
    1.1718
    0.3093
    0.6429
    0.8640
    0.7975
    0.7781
    0.4385
    0.6359
    0.6441
    0.6117
    0.3077
    0.4893
    0.5204
    0.7485

current state : 5 next state : 20 taken action : 10000000   5000000
 next reward : 0.014131
iteration: 83
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0356
   -0.0219
   -0.0017
    1.7546
    1.4823
    1.1718
    0.3093
    0.6429
    0.8640
    0.7975
    0.7781
    0.4385
    0.6359
    0.6441
    0.6117
    0.3077
    0.4893
    0.5204
    0.7485

current state : 20 next state : 2 taken action : 0  1000000
 next reward : 3.4552e-09
iteration: 84
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0356
   -0.0219
   -0.0017
    1.7546
    1.5712
    1.1718
    0.3093
    0.6429
    0.8640
    0.7975
    0.7781
    0.4385
    0.6359
    0.6441
    0.6117
    0.3077
    0.4893
    0.5204
    0.7485

current state : 2 next state : 6 taken action : 2500000  1000000
 next reward : 0.57578
iteration: 85
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0356
   -0.0219
   -0.0017
    1.6512
    1.5712
    1.1718
    0.3093
    0.6429
    0.8640
    0.7975
    0.7781
    0.4385
    0.6359
    0.6441
    0.6117
    0.3077
    0.4893
    0.5204
    0.7485

current state : 6 next state : 5 taken action : 2500000        0
 next reward : 1
iteration: 86
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0356
   -0.0219
   -0.0017
    1.6512
    1.5712
    1.1718
    0.3093
    0.6429
    0.8640
    0.7975
    0.7781
    0.4385
    0.6359
    0.6461
    0.6117
    0.3077
    0.4893
    0.5204
    0.7485

current state : 5 next state : 15 taken action : 7500000  2500000
 next reward : 0.0091716
iteration: 87
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0356
   -0.0219
   -0.0017
    1.6512
    1.5712
    1.1718
    0.3093
    0.6429
    0.8640
    0.7975
    0.7781
    0.4385
    0.6359
    0.6461
    0.5954
    0.3077
    0.4893
    0.5204
    0.7485

current state : 15 next state : 16 taken action : 7500000  5000000
 next reward : 0.0060955
iteration: 88
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0356
   -0.0219
   -0.0017
    1.6512
    1.5712
    1.1718
    0.3093
    0.6429
    0.8640
    0.7975
    0.7781
    0.4396
    0.6359
    0.6461
    0.5954
    0.3077
    0.4893
    0.5204
    0.7485

current state : 16 next state : 13 taken action : 7500000        0
 next reward : 0.0013375
iteration: 89
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0356
   -0.0219
   -0.0017
    1.6512
    1.5623
    1.1718
    0.3093
    0.6429
    0.8640
    0.7975
    0.7781
    0.4396
    0.6359
    0.6461
    0.5954
    0.3077
    0.4893
    0.5204
    0.7485

current state : 13 next state : 6 taken action : 2500000  1000000
 next reward : 0.75847
iteration: 90
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0219
   -0.0017
    1.6512
    1.5623
    1.1718
    0.3093
    0.6429
    0.8640
    0.7975
    0.7781
    0.4396
    0.6359
    0.6461
    0.5954
    0.3077
    0.4893
    0.5204
    0.7485

current state : 6 next state : 2 taken action : 0  1000000
 next reward : 1.8515e-09
iteration: 91
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0219
   -0.0017
    1.6512
    1.5978
    1.1718
    0.3093
    0.6429
    0.8640
    0.7975
    0.7781
    0.4396
    0.6359
    0.6461
    0.5954
    0.3077
    0.4893
    0.5204
    0.7485

current state : 2 next state : 6 taken action : 2500000  1000000
 next reward : 0.84859
iteration: 92
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.6512
    1.5978
    1.1718
    0.3093
    0.6429
    0.8640
    0.7975
    0.7781
    0.4396
    0.6359
    0.6461
    0.5954
    0.3077
    0.4893
    0.5204
    0.7485

current state : 6 next state : 3 taken action : 0  2500000
 next reward : -3.6669e-10
iteration: 93
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.6512
    1.5978
    1.1718
    0.3093
    0.6429
    0.8640
    0.7975
    0.7781
    0.4425
    0.6359
    0.6461
    0.5954
    0.3077
    0.4893
    0.5204
    0.7485

current state : 3 next state : 13 taken action : 7500000        0
 next reward : 0.0013822
iteration: 94
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.6512
    1.5978
    1.1718
    0.3093
    0.6429
    0.8640
    0.7975
    0.7122
    0.4425
    0.6359
    0.6461
    0.5954
    0.3077
    0.4893
    0.5204
    0.7485

current state : 13 next state : 12 taken action : 5000000  5000000
 next reward : 0.014935
iteration: 95
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.6512
    1.5978
    1.1718
    0.3093
    0.6429
    0.8702
    0.7975
    0.7122
    0.4425
    0.6359
    0.6461
    0.5954
    0.3077
    0.4893
    0.5204
    0.7485

current state : 12 next state : 10 taken action : 5000000  1000000
 next reward : 0.040655
iteration: 96
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.6512
    1.5978
    1.1718
    0.3093
    0.6429
    0.8702
    0.7975
    0.6680
    0.4425
    0.6359
    0.6461
    0.5954
    0.3077
    0.4893
    0.5204
    0.7485

current state : 10 next state : 12 taken action : 5000000  5000000
 next reward : 0.010839
iteration: 97
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5727
    1.5978
    1.1718
    0.3093
    0.6429
    0.8702
    0.7975
    0.6680
    0.4425
    0.6359
    0.6461
    0.5954
    0.3077
    0.4893
    0.5204
    0.7485

current state : 12 next state : 5 taken action : 2500000        0
 next reward : 0.92376
iteration: 98
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5727
    1.5978
    1.1718
    0.3093
    0.6429
    0.8702
    0.7975
    0.6379
    0.4425
    0.6359
    0.6461
    0.5954
    0.3077
    0.4893
    0.5204
    0.7485

current state : 5 next state : 12 taken action : 5000000  5000000
 next reward : 0.010143
iteration: 99
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5116
    1.5978
    1.1718
    0.3093
    0.6429
    0.8702
    0.7975
    0.6379
    0.4425
    0.6359
    0.6461
    0.5954
    0.3077
    0.4893
    0.5204
    0.7485

current state : 12 next state : 5 taken action : 2500000        0
 next reward : 0.75782
iteration: 100
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5116
    1.5978
    1.1718
    0.3146
    0.6429
    0.8702
    0.7975
    0.6379
    0.4425
    0.6359
    0.6461
    0.5954
    0.3077
    0.4893
    0.5204
    0.7485

current state : 5 next state : 8 taken action : 2500000  5000000
 next reward : 0.00029584
iteration: 101
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5116
    1.5978
    1.1718
    0.3146
    0.6429
    0.8702
    0.7975
    0.6379
    0.4425
    0.6359
    0.6461
    0.5954
    0.3077
    0.4893
    0.5204
    0.6970

current state : 8 next state : 20 taken action : 10000000   5000000
 next reward : 0.015798
iteration: 102
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5116
    1.5978
    1.1718
    0.3146
    0.6429
    0.8702
    0.7975
    0.6379
    0.4424
    0.6359
    0.6461
    0.5954
    0.3077
    0.4893
    0.5204
    0.6970

current state : 20 next state : 13 taken action : 7500000        0
 next reward : 0.0016279
iteration: 103
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5116
    1.5877
    1.1718
    0.3146
    0.6429
    0.8702
    0.7975
    0.6379
    0.4424
    0.6359
    0.6461
    0.5954
    0.3077
    0.4893
    0.5204
    0.6970

current state : 13 next state : 6 taken action : 2500000  1000000
 next reward : 1
iteration: 104
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5116
    1.5877
    1.1718
    0.3146
    0.6429
    0.8702
    0.7975
    0.6379
    0.4423
    0.6359
    0.6461
    0.5954
    0.3077
    0.4893
    0.5204
    0.6970

current state : 6 next state : 13 taken action : 7500000        0
 next reward : 0.0016782
iteration: 105
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5116
    1.5877
    1.1718
    0.3146
    0.6429
    0.8702
    0.7975
    0.6379
    0.4423
    0.6359
    0.6461
    0.5954
    0.3077
    0.4893
    0.5192
    0.6970

current state : 13 next state : 19 taken action : 10000000   2500000
 next reward : 0.0037406
iteration: 106
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5116
    1.5877
    1.1718
    0.3146
    0.6429
    0.8702
    0.7975
    0.6379
    0.4423
    0.6359
    0.6461
    0.5954
    0.3077
    0.4893
    0.5192
    0.6594

current state : 19 next state : 20 taken action : 10000000   5000000
 next reward : 0.012355
iteration: 107
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5116
    1.5877
    1.1718
    0.3146
    0.6429
    0.8702
    0.7975
    0.6379
    0.4423
    0.6359
    0.6461
    0.5954
    0.3077
    0.4893
    0.5192
    0.6594

current state : 20 next state : 1 taken action : 0  0
 next reward : 0
iteration: 108
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5116
    1.5877
    1.1718
    0.3146
    0.6429
    0.8702
    0.7975
    0.6379
    0.4423
    0.6065
    0.6461
    0.5954
    0.3077
    0.4893
    0.5192
    0.6594

current state : 1 next state : 14 taken action : 7500000  1000000
 next reward : 0.0081341
iteration: 109
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5116
    1.5877
    1.1718
    0.3146
    0.6429
    0.8702
    0.7975
    0.6379
    0.4423
    0.6065
    0.6461
    0.5954
    0.3077
    0.4893
    0.5192
    0.6307

current state : 14 next state : 20 taken action : 10000000   5000000
 next reward : 0.0098904
iteration: 110
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5116
    1.5877
    1.1718
    0.3146
    0.6429
    0.8702
    0.7975
    0.6379
    0.4423
    0.6065
    0.6461
    0.5954
    0.3077
    0.4890
    0.5192
    0.6307

current state : 20 next state : 18 taken action : 10000000   1000000
 next reward : 0.0027726
iteration: 111
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5116
    1.5877
    1.1718
    0.3146
    0.6429
    0.8702
    0.7975
    0.6379
    0.4423
    0.6065
    0.6461
    0.5954
    0.3077
    0.4890
    0.5192
    0.6307

current state : 18 next state : 1 taken action : 0  0
 next reward : 0
iteration: 112
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5116
    1.5877
    1.1718
    0.3146
    0.6429
    0.8702
    0.7975
    0.6379
    0.4423
    0.5880
    0.6461
    0.5954
    0.3077
    0.4890
    0.5192
    0.6307

current state : 1 next state : 14 taken action : 7500000  1000000
 next reward : 0.0069679
iteration: 113
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5116
    1.5877
    1.1718
    0.3146
    0.6429
    0.8702
    0.7975
    0.6379
    0.4423
    0.5880
    0.6461
    0.5954
    0.3077
    0.4890
    0.5192
    0.6307

current state : 14 next state : 1 taken action : 0  0
 next reward : 0
iteration: 114
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5116
    1.5877
    1.1718
    0.3146
    0.6429
    0.8702
    0.7975
    0.6379
    0.4423
    0.5880
    0.6461
    0.5954
    0.2970
    0.4890
    0.5192
    0.6307

current state : 1 next state : 17 taken action : 10000000         0
 next reward : 0.0002291
iteration: 115
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5116
    1.5877
    1.1718
    0.3146
    0.6429
    0.8702
    0.7975
    0.6379
    0.4423
    0.5880
    0.6449
    0.5954
    0.2970
    0.4890
    0.5192
    0.6307

current state : 17 next state : 15 taken action : 7500000  2500000
 next reward : 0.011059
iteration: 116
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5116
    1.5877
    1.1718
    0.3146
    0.6431
    0.8702
    0.7975
    0.6379
    0.4423
    0.5880
    0.6449
    0.5954
    0.2970
    0.4890
    0.5192
    0.6307

current state : 15 next state : 9 taken action : 5000000        0
 next reward : 0.010899
iteration: 117
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5116
    1.5877
    1.1718
    0.3146
    0.6431
    0.8702
    0.7975
    0.6379
    0.4423
    0.5962
    0.6449
    0.5954
    0.2970
    0.4890
    0.5192
    0.6307

current state : 9 next state : 14 taken action : 7500000  1000000
 next reward : 0.0074646
iteration: 118
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5116
    1.5877
    1.1718
    0.3146
    0.6431
    0.8702
    0.7959
    0.6379
    0.4423
    0.5962
    0.6449
    0.5954
    0.2970
    0.4890
    0.5192
    0.6307

current state : 14 next state : 11 taken action : 5000000  2500000
 next reward : 0.031665
iteration: 119
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5116
    1.5877
    1.1718
    0.3146
    0.6431
    0.8702
    0.7959
    0.6379
    0.4423
    0.5962
    0.6449
    0.5954
    0.2970
    0.4890
    0.5192
    0.6307

current state : 11 next state : 9 taken action : 5000000        0
 next reward : 0.010903
iteration: 120
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5116
    1.5877
    1.1718
    0.3146
    0.6431
    0.8702
    0.7959
    0.6379
    0.4423
    0.6020
    0.6449
    0.5954
    0.2970
    0.4890
    0.5192
    0.6307

current state : 9 next state : 14 taken action : 7500000  1000000
 next reward : 0.0078365
iteration: 121
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5116
    1.5877
    1.1718
    0.3129
    0.6431
    0.8702
    0.7959
    0.6379
    0.4423
    0.6020
    0.6449
    0.5954
    0.2970
    0.4890
    0.5192
    0.6307

current state : 14 next state : 8 taken action : 2500000  5000000
 next reward : 0.00029743
iteration: 122
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5116
    1.5877
    1.1072
    0.3129
    0.6431
    0.8702
    0.7959
    0.6379
    0.4423
    0.6020
    0.6449
    0.5954
    0.2970
    0.4890
    0.5192
    0.6307

current state : 8 next state : 7 taken action : 2500000  2500000
 next reward : 0.1649
iteration: 123
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5116
    1.5877
    1.1072
    0.3129
    0.6431
    0.8702
    0.7959
    0.6379
    0.4423
    0.6020
    0.6449
    0.5954
    0.2970
    0.4890
    0.5192
    0.6307

current state : 7 next state : 1 taken action : 0  0
 next reward : 0
iteration: 124
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5116
    1.5877
    1.1072
    0.3129
    0.6431
    0.9394
    0.7959
    0.6379
    0.4423
    0.6020
    0.6449
    0.5954
    0.2970
    0.4890
    0.5192
    0.6307

current state : 1 next state : 10 taken action : 5000000  1000000
 next reward : 0.072527
iteration: 125
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5116
    1.5877
    1.1072
    0.3129
    0.6431
    0.9394
    0.7959
    0.6149
    0.4423
    0.6020
    0.6449
    0.5954
    0.2970
    0.4890
    0.5192
    0.6307

current state : 10 next state : 12 taken action : 5000000  5000000
 next reward : 0.0087119
iteration: 126
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.5116
    1.5877
    1.1072
    0.3129
    0.6431
    0.9394
    0.7959
    0.6149
    0.4423
    0.6020
    0.6456
    0.5954
    0.2970
    0.4890
    0.5192
    0.6307

current state : 12 next state : 15 taken action : 7500000  2500000
 next reward : 0.011115
iteration: 127
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
   -0.0017
    1.4628
    1.5877
    1.1072
    0.3129
    0.6431
    0.9394
    0.7959
    0.6149
    0.4423
    0.6020
    0.6456
    0.5954
    0.2970
    0.4890
    0.5192
    0.6307

current state : 15 next state : 5 taken action : 2500000        0
 next reward : 0.66379
iteration: 128
epsilon =
    0.6718

MeanR =
   1.0e+04 *

         0
    0.0296
   -0.0214
    0.0026
    1.4628
    1.5877
    1.1072
    0.3129
    0.6431
    0.9394
    0.7959
    0.6149
    0.4423
    0.6020
    0.6456
    0.5954
    0.2970
    0.4890
    0.5192
    0.6307

current state : 5 next state : 4 taken action : 0  5000000
 next reward : 1.1311e-14
iteration: 129
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0214
    0.0026
    1.4628
    1.5877
    1.1072
    0.3129
    0.6431
    0.9394
    0.7959
    0.6149
    0.4423
    0.6020
    0.6456
    0.5954
    0.2970
    0.4890
    0.5192
    0.6307

current state : 4 next state : 2 taken action : 0  1000000
 next reward : 4.3838e-09
iteration: 130
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0026
    1.4628
    1.5877
    1.1072
    0.3129
    0.6431
    0.9394
    0.7959
    0.6149
    0.4423
    0.6020
    0.6456
    0.5954
    0.2970
    0.4890
    0.5192
    0.6307

current state : 2 next state : 3 taken action : 0  2500000
 next reward : -5.7511e-10
iteration: 131
epsilon =
    0.6718

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0026
    1.4628
    1.5877
    1.1072
    0.3129
    0.6431
    0.9394
    0.8026
    0.6149
    0.4423
    0.6020
    0.6456
    0.5954
    0.2970
    0.4890
    0.5192
    0.6307

current state : 3 next state : 11 taken action : 5000000  2500000
 next reward : 0.033009
iteration: 132
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0026
    1.4628
    1.5877
    1.1072
    0.3129
    0.6431
    0.9394
    0.8026
    0.6149
    0.4423
    0.6059
    0.6456
    0.5954
    0.2970
    0.4890
    0.5192
    0.6307

current state : 11 next state : 14 taken action : 7500000  1000000
 next reward : 0.0080926
iteration: 133
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0026
    1.4628
    1.5877
    1.0649
    0.3129
    0.6431
    0.9394
    0.8026
    0.6149
    0.4423
    0.6059
    0.6456
    0.5954
    0.2970
    0.4890
    0.5192
    0.6307

current state : 14 next state : 7 taken action : 2500000  2500000
 next reward : 0.13576
iteration: 134
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0026
    1.4628
    1.5877
    1.0649
    0.3137
    0.6431
    0.9394
    0.8026
    0.6149
    0.4423
    0.6059
    0.6456
    0.5954
    0.2970
    0.4890
    0.5192
    0.6307

current state : 7 next state : 8 taken action : 2500000  5000000
 next reward : 0.00030114
iteration: 135
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.4628
    1.5877
    1.0649
    0.3137
    0.6431
    0.9394
    0.8026
    0.6149
    0.4423
    0.6059
    0.6456
    0.5954
    0.2970
    0.4890
    0.5192
    0.6307

current state : 8 next state : 4 taken action : 0  5000000
 next reward : 1.7692e-15
iteration: 136
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.4628
    1.5877
    1.0346
    0.3137
    0.6431
    0.9394
    0.8026
    0.6149
    0.4423
    0.6059
    0.6456
    0.5954
    0.2970
    0.4890
    0.5192
    0.6307

current state : 4 next state : 7 taken action : 2500000  2500000
 next reward : 0.11747
iteration: 137
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.4231
    1.5877
    1.0346
    0.3137
    0.6431
    0.9394
    0.8026
    0.6149
    0.4423
    0.6059
    0.6456
    0.5954
    0.2970
    0.4890
    0.5192
    0.6307

current state : 7 next state : 5 taken action : 2500000        0
 next reward : 0.57852
iteration: 138
epsilon =
    0.5485

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.4231
    1.5877
    1.0346
    0.3156
    0.6431
    0.9394
    0.8026
    0.6149
    0.4423
    0.6059
    0.6456
    0.5954
    0.2970
    0.4890
    0.5192
    0.6307

current state : 5 next state : 8 taken action : 2500000  5000000
 next reward : 0.00031029
iteration: 139
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.4231
    1.5877
    1.0346
    0.3156
    0.6431
    0.9394
    0.8022
    0.6149
    0.4423
    0.6059
    0.6456
    0.5954
    0.2970
    0.4890
    0.5192
    0.6307

current state : 8 next state : 11 taken action : 5000000  2500000
 next reward : 0.032937
iteration: 140
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.4231
    1.5877
    1.0346
    0.3156
    0.6431
    0.9394
    0.8022
    0.6149
    0.4423
    0.6059
    0.6456
    0.5954
    0.2970
    0.4891
    0.5192
    0.6307

current state : 11 next state : 18 taken action : 10000000   1000000
 next reward : 0.0027737
iteration: 141
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.4231
    1.5877
    1.0346
    0.3156
    0.6431
    0.9394
    0.8008
    0.6149
    0.4423
    0.6059
    0.6456
    0.5954
    0.2970
    0.4891
    0.5192
    0.6307

current state : 18 next state : 11 taken action : 5000000  2500000
 next reward : 0.032645
iteration: 142
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.4231
    1.5877
    1.0346
    0.3156
    0.6431
    0.9394
    0.8008
    0.6149
    0.4423
    0.6059
    0.6456
    0.5954
    0.2970
    0.4891
    0.5192
    0.6093

current state : 11 next state : 20 taken action : 10000000   5000000
 next reward : 0.0083226
iteration: 143
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.4231
    1.5877
    1.0346
    0.3156
    0.6431
    0.9394
    0.8008
    0.6149
    0.4423
    0.6059
    0.6456
    0.5954
    0.2970
    0.4891
    0.5192
    0.5919

current state : 20 next state : 20 taken action : 10000000   5000000
 next reward : 0.0072006
iteration: 144
epsilon =
    0.6718

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.4231
    1.5877
    1.0346
    0.3156
    0.6431
    0.9394
    0.8008
    0.6149
    0.4423
    0.6059
    0.6456
    0.5954
    0.2970
    0.4891
    0.5192
    0.5919

current state : 20 next state : 15 taken action : 7500000  2500000
 next reward : 0.011117
iteration: 145
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.4231
    1.5717
    1.0346
    0.3156
    0.6431
    0.9394
    0.8008
    0.6149
    0.4423
    0.6059
    0.6456
    0.5954
    0.2970
    0.4891
    0.5192
    0.5919

current state : 15 next state : 6 taken action : 2500000  1000000
 next reward : 1
iteration: 146
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.4231
    1.5717
    1.0346
    0.3156
    0.6431
    0.9394
    0.7985
    0.6149
    0.4423
    0.6059
    0.6456
    0.5954
    0.2970
    0.4891
    0.5192
    0.5919

current state : 6 next state : 11 taken action : 5000000  2500000
 next reward : 0.033859
iteration: 147
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.4231
    1.5717
    1.0346
    0.3148
    0.6431
    0.9394
    0.7985
    0.6149
    0.4423
    0.6059
    0.6456
    0.5954
    0.2970
    0.4891
    0.5192
    0.5919

current state : 11 next state : 8 taken action : 2500000  5000000
 next reward : 0.00032252
iteration: 148
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.4231
    1.5717
    1.0346
    0.3148
    0.6431
    0.9394
    0.7985
    0.6149
    0.4428
    0.6059
    0.6456
    0.5954
    0.2970
    0.4891
    0.5192
    0.5919

current state : 8 next state : 13 taken action : 7500000        0
 next reward : 0.0017743
iteration: 149
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.4231
    1.5717
    1.0346
    0.3148
    0.6431
    0.9394
    0.7985
    0.6149
    0.4428
    0.6059
    0.6456
    0.5813
    0.2970
    0.4891
    0.5192
    0.5919

current state : 13 next state : 16 taken action : 7500000  5000000
 next reward : 0.006923
iteration: 150
epsilon =
    0.6718

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.4231
    1.5717
    1.0117
    0.3148
    0.6431
    0.9394
    0.7985
    0.6149
    0.4428
    0.6059
    0.6456
    0.5813
    0.2970
    0.4891
    0.5192
    0.5919

current state : 16 next state : 7 taken action : 2500000  2500000
 next reward : 0.11051
iteration: 151
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.4231
    1.5717
    1.0117
    0.3148
    0.6431
    0.9394
    0.7985
    0.5974
    0.4428
    0.6059
    0.6456
    0.5813
    0.2970
    0.4891
    0.5192
    0.5919

current state : 7 next state : 12 taken action : 5000000  5000000
 next reward : 0.0079347
iteration: 152
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.4231
    1.5717
    0.9933
    0.3148
    0.6431
    0.9394
    0.7985
    0.5974
    0.4428
    0.6059
    0.6456
    0.5813
    0.2970
    0.4891
    0.5192
    0.5919

current state : 12 next state : 7 taken action : 2500000  2500000
 next reward : 0.10085
iteration: 153
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.4231
    1.5717
    0.9933
    0.3148
    0.6431
    0.9325
    0.7985
    0.5974
    0.4428
    0.6059
    0.6456
    0.5813
    0.2970
    0.4891
    0.5192
    0.5919

current state : 7 next state : 10 taken action : 5000000  1000000
 next reward : 0.07352
iteration: 154
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.4231
    1.5717
    0.9933
    0.3148
    0.6431
    0.9325
    0.7985
    0.5974
    0.4428
    0.6059
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5919

current state : 10 next state : 19 taken action : 10000000   2500000
 next reward : 0.0040089
iteration: 155
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.4231
    1.5597
    0.9933
    0.3148
    0.6431
    0.9325
    0.7985
    0.5974
    0.4428
    0.6059
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5919

current state : 19 next state : 6 taken action : 2500000  1000000
 next reward : 1
iteration: 156
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.3904
    1.5597
    0.9933
    0.3148
    0.6431
    0.9325
    0.7985
    0.5974
    0.4428
    0.6059
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5919

current state : 6 next state : 5 taken action : 2500000        0
 next reward : 0.56283
iteration: 157
epsilon =
    0.4750

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.3618
    1.5597
    0.9933
    0.3148
    0.6431
    0.9325
    0.7985
    0.5974
    0.4428
    0.6059
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5919

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.50738
iteration: 158
epsilon =
    0.4249

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.3618
    1.5597
    0.9933
    0.3148
    0.6431
    0.9325
    0.7985
    0.5974
    0.4428
    0.6059
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5919

current state : 5 next state : 1 taken action : 0  0
 next reward : 0
iteration: 159
epsilon =
    0.6718

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.3618
    1.5597
    1.0654
    0.3148
    0.6431
    0.9325
    0.7985
    0.5974
    0.4428
    0.6059
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5919

current state : 1 next state : 7 taken action : 2500000  2500000
 next reward : 0.14866
iteration: 160
epsilon =
    0.6718

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.3618
    1.5597
    1.0654
    0.3148
    0.6431
    0.9325
    0.7985
    0.5974
    0.4428
    0.6059
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5800

current state : 7 next state : 20 taken action : 10000000   5000000
 next reward : 0.0071111
iteration: 161
epsilon =
    0.5485

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.3618
    1.5597
    1.0654
    0.3148
    0.6431
    0.9325
    0.7985
    0.5974
    0.4427
    0.6059
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5800

current state : 20 next state : 13 taken action : 7500000        0
 next reward : 0.0018418
iteration: 162
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.3618
    1.5597
    1.0654
    0.3148
    0.6431
    0.9325
    0.7985
    0.5974
    0.4427
    0.6059
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5667

current state : 13 next state : 20 taken action : 10000000   5000000
 next reward : 0.0063287
iteration: 163
epsilon =
    0.4750

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0225
    0.0018
    1.3618
    1.5597
    1.0654
    0.3148
    0.6431
    0.9325
    0.7985
    0.5974
    0.4427
    0.6059
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5667

current state : 20 next state : 13 taken action : 7500000        0
 next reward : 0.0018412
iteration: 164
epsilon =
    0.6718

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0235
    0.0018
    1.3618
    1.5597
    1.0654
    0.3148
    0.6431
    0.9325
    0.7985
    0.5974
    0.4427
    0.6059
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5667

current state : 13 next state : 3 taken action : 0  2500000
 next reward : -7.6946e-10
iteration: 165
epsilon =
    0.5485

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0235
    0.0018
    1.3378
    1.5597
    1.0654
    0.3148
    0.6431
    0.9325
    0.7985
    0.5974
    0.4427
    0.6059
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5667

current state : 3 next state : 5 taken action : 2500000        0
 next reward : 0.46418
iteration: 166
epsilon =
    0.3878

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0235
    0.0018
    1.3166
    1.5597
    1.0654
    0.3148
    0.6431
    0.9325
    0.7985
    0.5974
    0.4427
    0.6059
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5667

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.42849
iteration: 167
epsilon =
    0.3591

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0238
    0.0018
    1.3166
    1.5597
    1.0654
    0.3148
    0.6431
    0.9325
    0.7985
    0.5974
    0.4427
    0.6059
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5667

current state : 5 next state : 3 taken action : 0  2500000
 next reward : -8.2957e-10
iteration: 168
epsilon =
    0.4750

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0238
    0.0018
    1.3166
    1.5597
    1.0654
    0.3148
    0.6431
    0.9325
    0.7985
    0.5974
    0.4427
    0.6102
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5667

current state : 3 next state : 14 taken action : 7500000  1000000
 next reward : 0.0091628
iteration: 169
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0238
    0.0018
    1.3166
    1.5597
    1.0654
    0.3148
    0.6431
    0.9325
    0.7985
    0.5974
    0.4430
    0.6102
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5667

current state : 14 next state : 13 taken action : 7500000        0
 next reward : 0.0018488
iteration: 170
epsilon =
    0.5485

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0238
    0.0018
    1.3166
    1.5597
    1.0654
    0.3148
    0.6431
    0.9325
    0.7985
    0.5974
    0.4430
    0.6102
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5553

current state : 13 next state : 20 taken action : 10000000   5000000
 next reward : 0.0057215
iteration: 171
epsilon =
    0.4249

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0238
    0.0018
    1.3166
    1.5597
    1.0654
    0.3148
    0.6431
    0.9325
    0.7985
    0.5974
    0.4430
    0.6102
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5553

current state : 20 next state : 1 taken action : 0  0
 next reward : 0
iteration: 172
epsilon =
    0.5485

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0238
    0.0018
    1.3166
    1.5597
    1.1424
    0.3148
    0.6431
    0.9325
    0.7985
    0.5974
    0.4430
    0.6102
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5553

current state : 1 next state : 7 taken action : 2500000  2500000
 next reward : 0.21075
iteration: 173
epsilon =
    0.5485

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0238
    0.0018
    1.3166
    1.5597
    1.1424
    0.3148
    0.6431
    0.9325
    0.7985
    0.5974
    0.4430
    0.6102
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5553

current state : 7 next state : 1 taken action : 0  0
 next reward : 0
iteration: 174
epsilon =
    0.4750

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0238
    0.0018
    1.3166
    1.5597
    1.2344
    0.3148
    0.6431
    0.9325
    0.7985
    0.5974
    0.4430
    0.6102
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5553

current state : 1 next state : 7 taken action : 2500000  2500000
 next reward : 0.31045
iteration: 175
epsilon =
    0.4750

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0238
    0.0018
    1.3959
    1.5597
    1.2344
    0.3148
    0.6431
    0.9325
    0.7985
    0.5974
    0.4430
    0.6102
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5553

current state : 7 next state : 5 taken action : 2500000        0
 next reward : 0.57409
iteration: 176
epsilon =
    0.3359

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0238
    0.0018
    1.3741
    1.5597
    1.2344
    0.3148
    0.6431
    0.9325
    0.7985
    0.5974
    0.4430
    0.6102
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5553

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.53058
iteration: 177
epsilon =
    0.3167

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0238
    0.0018
    1.3543
    1.5597
    1.2344
    0.3148
    0.6431
    0.9325
    0.7985
    0.5974
    0.4430
    0.6102
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5553

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.49361
iteration: 178
epsilon =
    0.3004

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0238
    0.0018
    1.3543
    1.5597
    1.2344
    0.3148
    0.6460
    0.9325
    0.7985
    0.5974
    0.4430
    0.6102
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5553

current state : 5 next state : 9 taken action : 5000000        0
 next reward : 0.012182
iteration: 179
epsilon =
    0.6718

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0245
    0.0018
    1.3543
    1.5597
    1.2344
    0.3148
    0.6460
    0.9325
    0.7985
    0.5974
    0.4430
    0.6102
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5553

current state : 9 next state : 3 taken action : 0  2500000
 next reward : -9.4673e-10
iteration: 180
epsilon =
    0.4249

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0245
    0.0018
    1.3370
    1.5597
    1.2344
    0.3148
    0.6460
    0.9325
    0.7985
    0.5974
    0.4430
    0.6102
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5553

current state : 3 next state : 5 taken action : 2500000        0
 next reward : 0.46286
iteration: 181
epsilon =
    0.2864

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0245
    0.0018
    1.3212
    1.5597
    1.2344
    0.3148
    0.6460
    0.9325
    0.7985
    0.5974
    0.4430
    0.6102
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5553

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.43601
iteration: 182
epsilon =
    0.2742

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0245
    0.0018
    1.3068
    1.5597
    1.2344
    0.3148
    0.6460
    0.9325
    0.7985
    0.5974
    0.4430
    0.6102
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5553

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.4128
iteration: 183
epsilon =
    0.2635

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0245
    0.0018
    1.3068
    1.5597
    1.2344
    0.3148
    0.6460
    0.9304
    0.7985
    0.5974
    0.4430
    0.6102
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5553

current state : 5 next state : 10 taken action : 5000000  1000000
 next reward : 0.075538
iteration: 184
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0245
    0.0018
    1.3068
    1.5597
    1.2344
    0.3148
    0.6460
    0.9260
    0.7985
    0.5974
    0.4430
    0.6102
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5553

current state : 10 next state : 10 taken action : 5000000  1000000
 next reward : 0.073774
iteration: 185
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0245
    0.0018
    1.3068
    1.5597
    1.2344
    0.3148
    0.6460
    0.9260
    0.7985
    0.5974
    0.4430
    0.6102
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5468

current state : 10 next state : 20 taken action : 10000000   5000000
 next reward : 0.0052935
iteration: 186
epsilon =
    0.3878

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0245
    0.0018
    1.3068
    1.5597
    1.2344
    0.3148
    0.6460
    0.9260
    0.7985
    0.5974
    0.4430
    0.6102
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5468

current state : 20 next state : 13 taken action : 7500000        0
 next reward : 0.0018472
iteration: 187
epsilon =
    0.4750

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0245
    0.0018
    1.3068
    1.5597
    1.2344
    0.3148
    0.6460
    0.9260
    0.7985
    0.5974
    0.4430
    0.6102
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5383

current state : 13 next state : 20 taken action : 10000000   5000000
 next reward : 0.0048958
iteration: 188
epsilon =
    0.3591

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0245
    0.0018
    1.3068
    1.5597
    1.2344
    0.3148
    0.6460
    0.9260
    0.7985
    0.5974
    0.4429
    0.6102
    0.6456
    0.5813
    0.2970
    0.4891
    0.5212
    0.5383

current state : 20 next state : 13 taken action : 7500000        0
 next reward : 0.0018463
iteration: 189
epsilon =
    0.4249

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0245
    0.0018
    1.3068
    1.5597
    1.2344
    0.3148
    0.6460
    0.9260
    0.7985
    0.5974
    0.4429
    0.6102
    0.6450
    0.5813
    0.2970
    0.4891
    0.5212
    0.5383

current state : 13 next state : 15 taken action : 7500000  2500000
 next reward : 0.012094
iteration: 190
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0338
   -0.0245
    0.0018
    1.3068
    1.5597
    1.2344
    0.3148
    0.6460
    0.9227
    0.7985
    0.5974
    0.4429
    0.6102
    0.6450
    0.5813
    0.2970
    0.4891
    0.5212
    0.5383

current state : 15 next state : 10 taken action : 5000000  1000000
 next reward : 0.072447
iteration: 191
epsilon =
    0.6718

MeanR =
   1.0e+04 *

         0
    0.0330
   -0.0245
    0.0018
    1.3068
    1.5597
    1.2344
    0.3148
    0.6460
    0.9227
    0.7985
    0.5974
    0.4429
    0.6102
    0.6450
    0.5813
    0.2970
    0.4891
    0.5212
    0.5383

current state : 10 next state : 2 taken action : 0  1000000
 next reward : 4.2229e-09
iteration: 192
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0330
   -0.0245
    0.0018
    1.3068
    1.5597
    1.2344
    0.3148
    0.6460
    0.9227
    0.7985
    0.5974
    0.4429
    0.6102
    0.6450
    0.5813
    0.2970
    0.4891
    0.5212
    0.5294

current state : 2 next state : 20 taken action : 10000000   5000000
 next reward : 0.0045028
iteration: 193
epsilon =
    0.3359

MeanR =
   1.0e+04 *

         0
    0.0330
   -0.0245
    0.0018
    1.3068
    1.5597
    1.2344
    0.3148
    0.6460
    0.9227
    0.7985
    0.5974
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4891
    0.5212
    0.5294

current state : 20 next state : 13 taken action : 7500000        0
 next reward : 0.001843
iteration: 194
epsilon =
    0.3878

MeanR =
   1.0e+04 *

         0
    0.0330
   -0.0245
    0.0018
    1.3068
    1.5597
    1.2344
    0.3148
    0.6460
    0.9227
    0.7985
    0.5974
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4891
    0.5212
    0.5294

current state : 13 next state : 1 taken action : 0  0
 next reward : 0
iteration: 195
epsilon =
    0.4249

MeanR =
   1.0e+04 *

         0
    0.0330
   -0.0245
    0.0018
    1.3068
    1.5597
    1.2482
    0.3148
    0.6460
    0.9227
    0.7985
    0.5974
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4891
    0.5212
    0.5294

current state : 1 next state : 7 taken action : 2500000  2500000
 next reward : 0.32817
iteration: 196
epsilon =
    0.4249

MeanR =
   1.0e+04 *

         0
    0.0330
   -0.0245
    0.0018
    1.2942
    1.5597
    1.2482
    0.3148
    0.6460
    0.9227
    0.7985
    0.5974
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4891
    0.5212
    0.5294

current state : 7 next state : 5 taken action : 2500000        0
 next reward : 0.3933
iteration: 197
epsilon =
    0.2539

MeanR =
   1.0e+04 *

         0
    0.0330
   -0.0245
    0.0018
    1.2822
    1.5597
    1.2482
    0.3148
    0.6460
    0.9227
    0.7985
    0.5974
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4891
    0.5212
    0.5294

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.37547
iteration: 198
epsilon =
    0.2453

MeanR =
   1.0e+04 *

         0
    0.0330
   -0.0245
    0.0018
    1.2713
    1.5597
    1.2482
    0.3148
    0.6460
    0.9227
    0.7985
    0.5974
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4891
    0.5212
    0.5294

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.3597
iteration: 199
epsilon =
    0.2375

MeanR =
   1.0e+04 *

         0
    0.0330
   -0.0247
    0.0018
    1.2713
    1.5597
    1.2482
    0.3148
    0.6460
    0.9227
    0.7985
    0.5974
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4891
    0.5212
    0.5294

current state : 5 next state : 3 taken action : 0  2500000
 next reward : -9.9291e-10
iteration: 200
epsilon =
    0.3878

MeanR =
   1.0e+04 *

         0
    0.0339
   -0.0247
    0.0018
    1.2713
    1.5597
    1.2482
    0.3148
    0.6460
    0.9227
    0.7985
    0.5974
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4891
    0.5212
    0.5294

current state : 3 next state : 2 taken action : 0  1000000
 next reward : 4.83e-09
iteration: 201
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0339
   -0.0247
    0.0018
    1.2713
    1.5597
    1.2482
    0.3148
    0.6460
    0.9227
    0.7985
    0.5974
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5294

current state : 2 next state : 18 taken action : 10000000   1000000
 next reward : 0.0029991
iteration: 202
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0339
   -0.0247
    0.0018
    1.2713
    1.5597
    1.2482
    0.3148
    0.6460
    0.9227
    0.7985
    0.5974
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 18 next state : 20 taken action : 10000000   5000000
 next reward : 0.004265
iteration: 203
epsilon =
    0.3167

MeanR =
   1.0e+04 *

         0
    0.0339
   -0.0247
    0.0018
    1.2713
    1.5597
    1.2482
    0.3148
    0.6460
    0.9227
    0.7980
    0.5974
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 20 next state : 11 taken action : 5000000  2500000
 next reward : 0.035048
iteration: 204
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0339
   -0.0247
    0.0018
    1.2614
    1.5597
    1.2482
    0.3148
    0.6460
    0.9227
    0.7980
    0.5974
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 11 next state : 5 taken action : 2500000        0
 next reward : 0.34593
iteration: 205
epsilon =
    0.2304

MeanR =
   1.0e+04 *

         0
    0.0339
   -0.0247
    0.0018
    1.2521
    1.5597
    1.2482
    0.3148
    0.6460
    0.9227
    0.7980
    0.5974
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.33335
iteration: 206
epsilon =
    0.2239

MeanR =
   1.0e+04 *

         0
    0.0339
   -0.0247
    0.0037
    1.2521
    1.5597
    1.2482
    0.3148
    0.6460
    0.9227
    0.7980
    0.5974
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 5 next state : 4 taken action : 0  5000000
 next reward : 7.766e-14
iteration: 207
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0339
   -0.0247
    0.0037
    1.2521
    1.5597
    1.2202
    0.3148
    0.6460
    0.9227
    0.7980
    0.5974
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 4 next state : 7 taken action : 2500000  2500000
 next reward : 0.293
iteration: 208
epsilon =
    0.3878

MeanR =
   1.0e+04 *

         0
    0.0339
   -0.0247
    0.0037
    1.2437
    1.5597
    1.2202
    0.3148
    0.6460
    0.9227
    0.7980
    0.5974
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 7 next state : 5 taken action : 2500000        0
 next reward : 0.32237
iteration: 209
epsilon =
    0.2179

MeanR =
   1.0e+04 *

         0
    0.0339
   -0.0247
    0.0037
    1.2357
    1.5597
    1.2202
    0.3148
    0.6460
    0.9227
    0.7980
    0.5974
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.31211
iteration: 210
epsilon =
    0.2124

MeanR =
   1.0e+04 *

         0
    0.0339
   -0.0247
    0.0037
    1.2282
    1.5597
    1.2202
    0.3148
    0.6460
    0.9227
    0.7980
    0.5974
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.3028
iteration: 211
epsilon =
    0.2073

MeanR =
   1.0e+04 *

         0
    0.0339
   -0.0247
    0.0037
    1.2213
    1.5597
    1.2202
    0.3148
    0.6460
    0.9227
    0.7980
    0.5974
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.29431
iteration: 212
epsilon =
    0.2025

MeanR =
   1.0e+04 *

         0
    0.0339
   -0.0247
    0.0037
    1.2148
    1.5597
    1.2202
    0.3148
    0.6460
    0.9227
    0.7980
    0.5974
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.28655
iteration: 213
epsilon =
    0.1981

MeanR =
   1.0e+04 *

         0
    0.0339
   -0.0247
    0.0037
    1.2087
    1.5597
    1.2202
    0.3148
    0.6460
    0.9227
    0.7980
    0.5974
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.27941
iteration: 214
epsilon =
    0.1939

MeanR =
   1.0e+04 *

         0
    0.0339
   -0.0247
    0.0037
    1.2029
    1.5597
    1.2202
    0.3148
    0.6460
    0.9227
    0.7980
    0.5974
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.27284
iteration: 215
epsilon =
    0.1900

MeanR =
   1.0e+04 *

         0
    0.0339
   -0.0247
    0.0037
    1.2029
    1.5597
    1.2202
    0.3148
    0.6483
    0.9227
    0.7980
    0.5974
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 5 next state : 9 taken action : 5000000        0
 next reward : 0.012404
iteration: 216
epsilon =
    0.5485

MeanR =
   1.0e+04 *

         0
    0.0339
   -0.0247
    0.0037
    1.2029
    1.5597
    1.2202
    0.3148
    0.6483
    0.9227
    0.7980
    0.5974
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 9 next state : 1 taken action : 0  0
 next reward : 0
iteration: 217
epsilon =
    0.3878

MeanR =
   1.0e+04 *

         0
    0.0339
   -0.0247
    0.0037
    1.2029
    1.5597
    1.2202
    0.3148
    0.6483
    0.9227
    0.7980
    0.5767
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 1 next state : 12 taken action : 5000000  5000000
 next reward : 0.0069127
iteration: 218
epsilon =
    0.6718

MeanR =
   1.0e+04 *

         0
    0.0339
   -0.0247
    0.0037
    1.2029
    1.5597
    1.1963
    0.3148
    0.6483
    0.9227
    0.7980
    0.5767
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 12 next state : 7 taken action : 2500000  2500000
 next reward : 0.26544
iteration: 219
epsilon =
    0.3591

MeanR =
   1.0e+04 *

         0
    0.0339
   -0.0247
    0.0037
    1.1977
    1.5597
    1.1963
    0.3148
    0.6483
    0.9227
    0.7980
    0.5767
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 7 next state : 5 taken action : 2500000        0
 next reward : 0.267
iteration: 220
epsilon =
    0.1863

MeanR =
   1.0e+04 *

         0
    0.0339
   -0.0247
    0.0037
    1.1926
    1.5597
    1.1963
    0.3148
    0.6483
    0.9227
    0.7980
    0.5767
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.26136
iteration: 221
epsilon =
    0.1828

MeanR =
   1.0e+04 *

         0
    0.0339
   -0.0247
    0.0037
    1.1878
    1.5597
    1.1963
    0.3148
    0.6483
    0.9227
    0.7980
    0.5767
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.25613
iteration: 222
epsilon =
    0.1795

MeanR =
   1.0e+04 *

         0
    0.0339
   -0.0247
    0.0037
    1.1878
    1.5597
    1.1963
    0.3148
    0.6483
    0.9227
    0.7980
    0.5659
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 5 next state : 12 taken action : 5000000  5000000
 next reward : 0.0062862
iteration: 223
epsilon =
    0.5485

MeanR =
   1.0e+04 *

         0
    0.0339
   -0.0247
    0.0037
    1.1878
    1.5597
    1.1746
    0.3148
    0.6483
    0.9227
    0.7980
    0.5659
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 12 next state : 7 taken action : 2500000  2500000
 next reward : 0.24224
iteration: 224
epsilon =
    0.3359

MeanR =
   1.0e+04 *

         0
    0.0339
   -0.0247
    0.0037
    1.1834
    1.5597
    1.1746
    0.3148
    0.6483
    0.9227
    0.7980
    0.5659
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 7 next state : 5 taken action : 2500000        0
 next reward : 0.25145
iteration: 225
epsilon =
    0.1764

MeanR =
   1.0e+04 *

         0
    0.0339
   -0.0247
    0.0037
    1.1834
    1.5597
    1.1578
    0.3148
    0.6483
    0.9227
    0.7980
    0.5659
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 5 next state : 7 taken action : 2500000  2500000
 next reward : 0.22538
iteration: 226
epsilon =
    0.3167

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0247
    0.0037
    1.1834
    1.5597
    1.1578
    0.3148
    0.6483
    0.9227
    0.7980
    0.5659
    0.4427
    0.6102
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 7 next state : 2 taken action : 0  1000000
 next reward : 4.1252e-09
iteration: 227
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0247
    0.0037
    1.1834
    1.5597
    1.1578
    0.3148
    0.6483
    0.9227
    0.7980
    0.5659
    0.4427
    0.6064
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 2 next state : 14 taken action : 7500000  1000000
 next reward : 0.0088847
iteration: 228
epsilon =
    0.6718

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0247
    0.0037
    1.1834
    1.5597
    1.1578
    0.3148
    0.6483
    0.9227
    0.7980
    0.5659
    0.4427
    0.6064
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 14 next state : 1 taken action : 0  0
 next reward : 0
iteration: 229
epsilon =
    0.3591

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0247
    0.0037
    1.2044
    1.5597
    1.1578
    0.3148
    0.6483
    0.9227
    0.7980
    0.5659
    0.4427
    0.6064
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 1 next state : 5 taken action : 2500000        0
 next reward : 0.27454
iteration: 230
epsilon =
    0.1734

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0247
    0.0037
    1.1997
    1.5597
    1.1578
    0.3148
    0.6483
    0.9227
    0.7980
    0.5659
    0.4427
    0.6064
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.26924
iteration: 231
epsilon =
    0.1706

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0247
    0.0037
    1.1952
    1.5597
    1.1578
    0.3148
    0.6483
    0.9227
    0.7980
    0.5659
    0.4427
    0.6064
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.26422
iteration: 232
epsilon =
    0.1679

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0247
    0.0037
    1.1909
    1.5597
    1.1578
    0.3148
    0.6483
    0.9227
    0.7980
    0.5659
    0.4427
    0.6064
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.25951
iteration: 233
epsilon =
    0.1654

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0247
    0.0037
    1.1909
    1.5597
    1.1430
    0.3148
    0.6483
    0.9227
    0.7980
    0.5659
    0.4427
    0.6064
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 5 next state : 7 taken action : 2500000  2500000
 next reward : 0.21129
iteration: 234
epsilon =
    0.3004

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0247
    0.0028
    1.1909
    1.5597
    1.1430
    0.3148
    0.6483
    0.9227
    0.7980
    0.5659
    0.4427
    0.6064
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 7 next state : 4 taken action : 0  5000000
 next reward : 1.7626e-14
iteration: 235
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0247
    0.0028
    1.1909
    1.5597
    1.1430
    0.3148
    0.6480
    0.9227
    0.7980
    0.5659
    0.4427
    0.6064
    0.6450
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 4 next state : 9 taken action : 5000000        0
 next reward : 0.012381
iteration: 236
epsilon =
    0.4750

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0247
    0.0028
    1.1909
    1.5597
    1.1430
    0.3148
    0.6480
    0.9227
    0.7980
    0.5659
    0.4427
    0.6064
    0.6449
    0.5813
    0.2970
    0.4880
    0.5212
    0.5236

current state : 9 next state : 15 taken action : 7500000  2500000
 next reward : 0.012084
iteration: 237
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0247
    0.0028
    1.1909
    1.5597
    1.1430
    0.3148
    0.6480
    0.9227
    0.7980
    0.5659
    0.4427
    0.6064
    0.6449
    0.5813
    0.2970
    0.4880
    0.5212
    0.5187

current state : 15 next state : 20 taken action : 10000000   5000000
 next reward : 0.0040685
iteration: 238
epsilon =
    0.3004

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0247
    0.0028
    1.1909
    1.5597
    1.1430
    0.3148
    0.6480
    0.9227
    0.7975
    0.5659
    0.4427
    0.6064
    0.6449
    0.5813
    0.2970
    0.4880
    0.5212
    0.5187

current state : 20 next state : 11 taken action : 5000000  2500000
 next reward : 0.034953
iteration: 239
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0247
    0.0028
    1.1909
    1.5597
    1.1430
    0.3148
    0.6480
    0.9227
    0.7975
    0.5659
    0.4427
    0.6064
    0.6449
    0.5813
    0.2970
    0.4880
    0.5212
    0.5187

current state : 11 next state : 1 taken action : 0  0
 next reward : 0
iteration: 240
epsilon =
    0.3359

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0247
    0.0028
    1.2145
    1.5597
    1.1430
    0.3148
    0.6480
    0.9227
    0.7975
    0.5659
    0.4427
    0.6064
    0.6449
    0.5813
    0.2970
    0.4880
    0.5212
    0.5187

current state : 1 next state : 5 taken action : 2500000        0
 next reward : 0.2862
iteration: 241
epsilon =
    0.1629

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0247
    0.0028
    1.2100
    1.5597
    1.1430
    0.3148
    0.6480
    0.9227
    0.7975
    0.5659
    0.4427
    0.6064
    0.6449
    0.5813
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.28097
iteration: 242
epsilon =
    0.1606

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0247
    0.0028
    1.2057
    1.5597
    1.1430
    0.3148
    0.6480
    0.9227
    0.7975
    0.5659
    0.4427
    0.6064
    0.6449
    0.5813
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.27598
iteration: 243
epsilon =
    0.1583

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0247
    0.0028
    1.2015
    1.5597
    1.1430
    0.3148
    0.6480
    0.9227
    0.7975
    0.5659
    0.4427
    0.6064
    0.6449
    0.5813
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.27127
iteration: 244
epsilon =
    0.1562

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0247
    0.0028
    1.1976
    1.5597
    1.1430
    0.3148
    0.6480
    0.9227
    0.7975
    0.5659
    0.4427
    0.6064
    0.6449
    0.5813
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.26683
iteration: 245
epsilon =
    0.1541

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0247
    0.0028
    1.1976
    1.5597
    1.1430
    0.3148
    0.6499
    0.9227
    0.7975
    0.5659
    0.4427
    0.6064
    0.6449
    0.5813
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 9 taken action : 5000000        0
 next reward : 0.012555
iteration: 246
epsilon =
    0.4249

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0247
    0.0028
    1.1976
    1.5597
    1.1430
    0.3148
    0.6499
    0.9227
    0.7975
    0.5659
    0.4427
    0.6064
    0.6449
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 9 next state : 16 taken action : 7500000  5000000
 next reward : 0.0065228
iteration: 247
epsilon =
    0.5485

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0247
    0.0028
    1.1976
    1.5597
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4427
    0.6064
    0.6449
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 16 next state : 8 taken action : 2500000  5000000
 next reward : 0.00033218
iteration: 248
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0247
    0.0028
    1.1976
    1.5484
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4427
    0.6064
    0.6449
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 8 next state : 6 taken action : 2500000  1000000
 next reward : 1
iteration: 249
epsilon =
    0.6718

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0247
    0.0028
    1.1940
    1.5484
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4427
    0.6064
    0.6449
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 6 next state : 5 taken action : 2500000        0
 next reward : 0.27266
iteration: 250
epsilon =
    0.1521

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0247
    0.0028
    1.1904
    1.5484
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4427
    0.6064
    0.6449
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.26853
iteration: 251
epsilon =
    0.1502

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0247
    0.0028
    1.1904
    1.5484
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4427
    0.6064
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 15 taken action : 7500000  2500000
 next reward : 0.012598
iteration: 252
epsilon =
    0.6718

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1904
    1.5484
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4427
    0.6064
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 15 next state : 3 taken action : 0  2500000
 next reward : -9.0923e-10
iteration: 253
epsilon =
    0.3591

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1870
    1.5484
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4427
    0.6064
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 3 next state : 5 taken action : 2500000        0
 next reward : 0.26474
iteration: 254
epsilon =
    0.1484

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1836
    1.5484
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4427
    0.6064
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.26102
iteration: 255
epsilon =
    0.1466

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1804
    1.5484
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4427
    0.6064
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.25749
iteration: 256
epsilon =
    0.1449

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1773
    1.5484
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4427
    0.6064
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.25413
iteration: 257
epsilon =
    0.1432

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1743
    1.5484
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4427
    0.6064
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.25093
iteration: 258
epsilon =
    0.1416

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1715
    1.5484
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4427
    0.6064
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.24787
iteration: 259
epsilon =
    0.1401

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1687
    1.5484
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4427
    0.6064
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.24496
iteration: 260
epsilon =
    0.1386

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1687
    1.5484
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4427
    0.6096
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 14 taken action : 7500000  1000000
 next reward : 0.0094562
iteration: 261
epsilon =
    0.5485

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1687
    1.5484
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4427
    0.6096
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 14 next state : 1 taken action : 0  0
 next reward : 0
iteration: 262
epsilon =
    0.3167

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1687
    1.5484
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4381
    0.6096
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 1 next state : 13 taken action : 7500000        0
 next reward : 0.0018127
iteration: 263
epsilon =
    0.3591

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1660
    1.5484
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4381
    0.6096
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 13 next state : 5 taken action : 2500000        0
 next reward : 0.24218
iteration: 264
epsilon =
    0.1371

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1635
    1.5484
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4381
    0.6096
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.23951
iteration: 265
epsilon =
    0.1357

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1610
    1.5484
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4381
    0.6096
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.23697
iteration: 266
epsilon =
    0.1344

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1586
    1.5484
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4381
    0.6096
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.23452
iteration: 267
epsilon =
    0.1330

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1562
    1.5484
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4381
    0.6096
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.23218
iteration: 268
epsilon =
    0.1317

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1540
    1.5484
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4381
    0.6096
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.22994
iteration: 269
epsilon =
    0.1305

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1518
    1.5484
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4381
    0.6096
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.22778
iteration: 270
epsilon =
    0.1293

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1497
    1.5484
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4381
    0.6096
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.22571
iteration: 271
epsilon =
    0.1281

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1477
    1.5484
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4381
    0.6096
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.22372
iteration: 272
epsilon =
    0.1269

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1457
    1.5484
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4381
    0.6096
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.2218
iteration: 273
epsilon =
    0.1258

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1438
    1.5484
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4381
    0.6096
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.21995
iteration: 274
epsilon =
    0.1247

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1419
    1.5484
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4381
    0.6096
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.21817
iteration: 275
epsilon =
    0.1237

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1401
    1.5484
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4381
    0.6096
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.21645
iteration: 276
epsilon =
    0.1226

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1401
    1.5425
    1.1430
    0.3143
    0.6499
    0.9227
    0.7975
    0.5659
    0.4381
    0.6096
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 6 taken action : 2500000  1000000
 next reward : 1
iteration: 277
epsilon =
    0.5485

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1401
    1.5425
    1.1430
    0.3143
    0.6499
    0.9189
    0.7975
    0.5659
    0.4381
    0.6096
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 6 next state : 10 taken action : 5000000  1000000
 next reward : 0.075037
iteration: 278
epsilon =
    0.5485

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1384
    1.5425
    1.1430
    0.3143
    0.6499
    0.9189
    0.7975
    0.5659
    0.4381
    0.6096
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 10 next state : 5 taken action : 2500000        0
 next reward : 0.21901
iteration: 279
epsilon =
    0.1216

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1384
    1.5374
    1.1430
    0.3143
    0.6499
    0.9189
    0.7975
    0.5659
    0.4381
    0.6096
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 6 taken action : 2500000  1000000
 next reward : 1
iteration: 280
epsilon =
    0.4750

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1369
    1.5374
    1.1430
    0.3143
    0.6499
    0.9189
    0.7975
    0.5659
    0.4381
    0.6096
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 6 next state : 5 taken action : 2500000        0
 next reward : 0.22113
iteration: 281
epsilon =
    0.1207

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1369
    1.5331
    1.1430
    0.3143
    0.6499
    0.9189
    0.7975
    0.5659
    0.4381
    0.6096
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5187

current state : 5 next state : 6 taken action : 2500000  1000000
 next reward : 1
iteration: 282
epsilon =
    0.4249

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1369
    1.5331
    1.1430
    0.3143
    0.6499
    0.9189
    0.7975
    0.5659
    0.4381
    0.6096
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5148

current state : 6 next state : 20 taken action : 10000000   5000000
 next reward : 0.0042695
iteration: 283
epsilon =
    0.2864

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1369
    1.5331
    1.1430
    0.3143
    0.6499
    0.9189
    0.7975
    0.5659
    0.4381
    0.6096
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5148

current state : 20 next state : 18 taken action : 10000000   1000000
 next reward : 0.0032681
iteration: 284
epsilon =
    0.6718

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1369
    1.5331
    1.1430
    0.3143
    0.6499
    0.9189
    0.7975
    0.5659
    0.4381
    0.6096
    0.6456
    0.5701
    0.2970
    0.4880
    0.5212
    0.5148

current state : 18 next state : 1 taken action : 0  0
 next reward : 0
iteration: 285
epsilon =
    0.3004

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1369
    1.5331
    1.1430
    0.3143
    0.6499
    0.9189
    0.7975
    0.5659
    0.4381
    0.6096
    0.6456
    0.5701
    0.2903
    0.4880
    0.5212
    0.5148

current state : 1 next state : 17 taken action : 10000000         0
 next reward : 0.00024349
iteration: 286
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1369
    1.5331
    1.1430
    0.3143
    0.6499
    0.9189
    0.7975
    0.5659
    0.4381
    0.6096
    0.6456
    0.5701
    0.2903
    0.4880
    0.5212
    0.5101

current state : 17 next state : 20 taken action : 10000000   5000000
 next reward : 0.0040774
iteration: 287
epsilon =
    0.2742

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1369
    1.5331
    1.1430
    0.3143
    0.6499
    0.9189
    0.7975
    0.5659
    0.4381
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 20 next state : 18 taken action : 10000000   1000000
 next reward : 0.003265
iteration: 288
epsilon =
    0.5485

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1369
    1.5331
    1.1430
    0.3143
    0.6499
    0.9189
    0.7975
    0.5659
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 18 next state : 13 taken action : 7500000        0
 next reward : 0.0019177
iteration: 289
epsilon =
    0.3359

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1369
    1.5331
    1.1430
    0.3143
    0.6499
    0.9189
    0.7975
    0.5659
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 13 next state : 1 taken action : 0  0
 next reward : 0
iteration: 290
epsilon =
    0.2864

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1369
    1.5331
    1.1430
    0.3143
    0.6499
    0.9189
    0.7975
    0.5503
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 1 next state : 12 taken action : 5000000  5000000
 next reward : 0.0059576
iteration: 291
epsilon =
    0.4750

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1369
    1.5331
    1.1281
    0.3143
    0.6499
    0.9189
    0.7975
    0.5503
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 12 next state : 7 taken action : 2500000  2500000
 next reward : 0.21576
iteration: 292
epsilon =
    0.2864

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0241
    0.0028
    1.1353
    1.5331
    1.1281
    0.3143
    0.6499
    0.9189
    0.7975
    0.5503
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 7 next state : 5 taken action : 2500000        0
 next reward : 0.22277
iteration: 293
epsilon =
    0.1197

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1353
    1.5331
    1.1281
    0.3143
    0.6499
    0.9189
    0.7975
    0.5503
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 3 taken action : 0  2500000
 next reward : -1e-09
iteration: 294
epsilon =
    0.3359

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1338
    1.5331
    1.1281
    0.3143
    0.6499
    0.9189
    0.7975
    0.5503
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 3 next state : 5 taken action : 2500000        0
 next reward : 0.22127
iteration: 295
epsilon =
    0.1187

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1338
    1.5294
    1.1281
    0.3143
    0.6499
    0.9189
    0.7975
    0.5503
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 6 taken action : 2500000  1000000
 next reward : 1
iteration: 296
epsilon =
    0.3878

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1324
    1.5294
    1.1281
    0.3143
    0.6499
    0.9189
    0.7975
    0.5503
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 6 next state : 5 taken action : 2500000        0
 next reward : 0.22256
iteration: 297
epsilon =
    0.1178

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1324
    1.5294
    1.1281
    0.3143
    0.6513
    0.9189
    0.7975
    0.5503
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 9 taken action : 5000000        0
 next reward : 0.014012
iteration: 298
epsilon =
    0.3878

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1324
    1.5294
    1.1281
    0.3143
    0.6513
    0.9189
    0.7975
    0.5427
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 9 next state : 12 taken action : 5000000  5000000
 next reward : 0.005626
iteration: 299
epsilon =
    0.4249

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1324
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5427
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 12 next state : 7 taken action : 2500000  2500000
 next reward : 0.20526
iteration: 300
epsilon =
    0.2742

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1310
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5427
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 7 next state : 5 taken action : 2500000        0
 next reward : 0.22116
iteration: 301
epsilon =
    0.1169

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1295
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5427
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.2197
iteration: 302
epsilon =
    0.1161

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1280
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5427
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.2183
iteration: 303
epsilon =
    0.1152

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1266
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5427
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.21693
iteration: 304
epsilon =
    0.1144

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1252
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5427
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.21561
iteration: 305
epsilon =
    0.1135

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1239
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5427
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.21433
iteration: 306
epsilon =
    0.1127

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1226
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5427
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.21309
iteration: 307
epsilon =
    0.1120

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1213
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5427
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.21188
iteration: 308
epsilon =
    0.1112

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1201
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5427
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.21071
iteration: 309
epsilon =
    0.1104

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1189
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5427
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.20957
iteration: 310
epsilon =
    0.1097

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1177
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5427
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.20846
iteration: 311
epsilon =
    0.1090

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1165
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5427
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.20738
iteration: 312
epsilon =
    0.1083

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1154
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5427
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.20633
iteration: 313
epsilon =
    0.1076

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1154
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 12 taken action : 5000000  5000000
 next reward : 0.005317
iteration: 314
epsilon =
    0.3878

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1143
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 12 next state : 5 taken action : 2500000        0
 next reward : 0.20535
iteration: 315
epsilon =
    0.1069

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1132
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.20436
iteration: 316
epsilon =
    0.1062

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1122
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.20339
iteration: 317
epsilon =
    0.1056

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1112
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.20245
iteration: 318
epsilon =
    0.1049

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1101
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.20153
iteration: 319
epsilon =
    0.1043

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1092
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.20064
iteration: 320
epsilon =
    0.1037

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1082
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.19976
iteration: 321
epsilon =
    0.1030

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1072
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.19891
iteration: 322
epsilon =
    0.1024

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1063
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.19808
iteration: 323
epsilon =
    0.1019

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1054
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.19727
iteration: 324
epsilon =
    0.1013

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1045
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.19648
iteration: 325
epsilon =
    0.1007

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1037
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.19571
iteration: 326
epsilon =
    0.1001

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1028
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.19496
iteration: 327
epsilon =
    0.0996

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1020
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.19422
iteration: 328
epsilon =
    0.0990

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1012
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1935
iteration: 329
epsilon =
    0.0985

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.1003
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.19279
iteration: 330
epsilon =
    0.0980

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.0996
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1921
iteration: 331
epsilon =
    0.0975

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.0988
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.19143
iteration: 332
epsilon =
    0.0970

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.0980
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.19077
iteration: 333
epsilon =
    0.0965

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.0973
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.19013
iteration: 334
epsilon =
    0.0960

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.0966
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1895
iteration: 335
epsilon =
    0.0955

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.0958
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.18888
iteration: 336
epsilon =
    0.0950

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.0951
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.18828
iteration: 337
epsilon =
    0.0945

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.0945
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.18768
iteration: 338
epsilon =
    0.0941

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.0938
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1871
iteration: 339
epsilon =
    0.0936

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.0931
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.18654
iteration: 340
epsilon =
    0.0932

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.0925
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.18598
iteration: 341
epsilon =
    0.0927

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.0925
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6096
    0.6461
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 15 taken action : 7500000  2500000
 next reward : 0.013457
iteration: 342
epsilon =
    0.5485

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.0925
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6114
    0.6461
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 15 next state : 14 taken action : 7500000  1000000
 next reward : 0.010211
iteration: 343
epsilon =
    0.4750

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.0925
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6114
    0.6461
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 14 next state : 1 taken action : 0  0
 next reward : 0
iteration: 344
epsilon =
    0.2742

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.0925
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6040
    0.6461
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 1 next state : 14 taken action : 7500000  1000000
 next reward : 0.0096108
iteration: 345
epsilon =
    0.4249

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.0925
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6040
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 14 next state : 15 taken action : 7500000  2500000
 next reward : 0.013406
iteration: 346
epsilon =
    0.4750

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.0925
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6060
    0.6456
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 15 next state : 14 taken action : 7500000  1000000
 next reward : 0.0097662
iteration: 347
epsilon =
    0.3878

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0243
    0.0028
    1.0925
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6060
    0.6454
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 14 next state : 15 taken action : 7500000  2500000
 next reward : 0.013388
iteration: 348
epsilon =
    0.4249

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0925
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6060
    0.6454
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 15 next state : 3 taken action : 0  2500000
 next reward : -9.1146e-10
iteration: 349
epsilon =
    0.3167

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0919
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6060
    0.6454
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 3 next state : 5 taken action : 2500000        0
 next reward : 0.18547
iteration: 350
epsilon =
    0.0923

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0912
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6060
    0.6454
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.18494
iteration: 351
epsilon =
    0.0918

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0906
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6060
    0.6454
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.18441
iteration: 352
epsilon =
    0.0914

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0900
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6060
    0.6454
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1839
iteration: 353
epsilon =
    0.0910

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0894
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6060
    0.6454
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.18339
iteration: 354
epsilon =
    0.0906

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0888
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6060
    0.6454
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1829
iteration: 355
epsilon =
    0.0902

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0882
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6060
    0.6454
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.18241
iteration: 356
epsilon =
    0.0898

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0877
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6060
    0.6454
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.18194
iteration: 357
epsilon =
    0.0894

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0871
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6060
    0.6454
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.18147
iteration: 358
epsilon =
    0.0890

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0866
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6060
    0.6454
    0.5701
    0.2903
    0.4879
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.18101
iteration: 359
epsilon =
    0.0886

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0866
    1.5294
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6060
    0.6454
    0.5701
    0.2903
    0.4882
    0.5212
    0.5101

current state : 5 next state : 18 taken action : 10000000   1000000
 next reward : 0.0033133
iteration: 360
epsilon =
    0.4750

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0866
    1.5257
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6060
    0.6454
    0.5701
    0.2903
    0.4882
    0.5212
    0.5101

current state : 18 next state : 6 taken action : 2500000  1000000
 next reward : 1
iteration: 361
epsilon =
    0.3591

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0861
    1.5257
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6060
    0.6454
    0.5701
    0.2903
    0.4882
    0.5212
    0.5101

current state : 6 next state : 5 taken action : 2500000        0
 next reward : 0.18282
iteration: 362
epsilon =
    0.0882

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0856
    1.5257
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6060
    0.6454
    0.5701
    0.2903
    0.4882
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.18238
iteration: 363
epsilon =
    0.0878

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0850
    1.5257
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6060
    0.6454
    0.5701
    0.2903
    0.4882
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.18193
iteration: 364
epsilon =
    0.0875

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0845
    1.5257
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6060
    0.6454
    0.5701
    0.2903
    0.4882
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1815
iteration: 365
epsilon =
    0.0871

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0840
    1.5257
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6060
    0.6454
    0.5701
    0.2903
    0.4882
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.18107
iteration: 366
epsilon =
    0.0867

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0835
    1.5257
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6060
    0.6454
    0.5701
    0.2903
    0.4882
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.18066
iteration: 367
epsilon =
    0.0864

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0830
    1.5257
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6060
    0.6454
    0.5701
    0.2903
    0.4882
    0.5212
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.18024
iteration: 368
epsilon =
    0.0860

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0830
    1.5257
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4882
    0.5212
    0.5101

current state : 5 next state : 14 taken action : 7500000  1000000
 next reward : 0.010077
iteration: 369
epsilon =
    0.3591

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0830
    1.5257
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4882
    0.5212
    0.5101

current state : 14 next state : 1 taken action : 0  0
 next reward : 0
iteration: 370
epsilon =
    0.2635

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0830
    1.5257
    1.1142
    0.3143
    0.6513
    0.9189
    0.7975
    0.5366
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4882
    0.5007
    0.5101

current state : 1 next state : 19 taken action : 10000000   2500000
 next reward : 0.003807
iteration: 371
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0830
    1.5257
    1.1142
    0.3143
    0.6513
    0.9189
    0.7966
    0.5366
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4882
    0.5007
    0.5101

current state : 19 next state : 11 taken action : 5000000  2500000
 next reward : 0.038807
iteration: 372
epsilon =
    0.6718

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0830
    1.5257
    1.1142
    0.3139
    0.6513
    0.9189
    0.7966
    0.5366
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4882
    0.5007
    0.5101

current state : 11 next state : 8 taken action : 2500000  5000000
 next reward : 0.00036857
iteration: 373
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0830
    1.5257
    1.1142
    0.3139
    0.6513
    0.9189
    0.7966
    0.5366
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4882
    0.5007
    0.5101

current state : 8 next state : 1 taken action : 0  0
 next reward : 0
iteration: 374
epsilon =
    0.2539

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0830
    1.5257
    1.1142
    0.3139
    0.6513
    0.9189
    0.7966
    0.5504
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4882
    0.5007
    0.5101

current state : 1 next state : 12 taken action : 5000000  5000000
 next reward : 0.0061094
iteration: 375
epsilon =
    0.3591

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0830
    1.5257
    1.1028
    0.3139
    0.6513
    0.9189
    0.7966
    0.5504
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4882
    0.5007
    0.5101

current state : 12 next state : 7 taken action : 2500000  2500000
 next reward : 0.19727
iteration: 376
epsilon =
    0.2635

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0826
    1.5257
    1.1028
    0.3139
    0.6513
    0.9189
    0.7966
    0.5504
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4882
    0.5007
    0.5101

current state : 7 next state : 5 taken action : 2500000        0
 next reward : 0.17989
iteration: 377
epsilon =
    0.0857

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0821
    1.5257
    1.1028
    0.3139
    0.6513
    0.9189
    0.7966
    0.5504
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4882
    0.5007
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17949
iteration: 378
epsilon =
    0.0853

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0816
    1.5257
    1.1028
    0.3139
    0.6513
    0.9189
    0.7966
    0.5504
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4882
    0.5007
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1791
iteration: 379
epsilon =
    0.0850

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0812
    1.5257
    1.1028
    0.3139
    0.6513
    0.9189
    0.7966
    0.5504
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4882
    0.5007
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17871
iteration: 380
epsilon =
    0.0846

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0807
    1.5257
    1.1028
    0.3139
    0.6513
    0.9189
    0.7966
    0.5504
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4882
    0.5007
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17833
iteration: 381
epsilon =
    0.0843

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0803
    1.5257
    1.1028
    0.3139
    0.6513
    0.9189
    0.7966
    0.5504
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4882
    0.5007
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17796
iteration: 382
epsilon =
    0.0840

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0798
    1.5257
    1.1028
    0.3139
    0.6513
    0.9189
    0.7966
    0.5504
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4882
    0.5007
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17759
iteration: 383
epsilon =
    0.0836

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0794
    1.5257
    1.1028
    0.3139
    0.6513
    0.9189
    0.7966
    0.5504
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4882
    0.5007
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17723
iteration: 384
epsilon =
    0.0833

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0789
    1.5257
    1.1028
    0.3139
    0.6513
    0.9189
    0.7966
    0.5504
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4882
    0.5007
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17688
iteration: 385
epsilon =
    0.0830

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0785
    1.5257
    1.1028
    0.3139
    0.6513
    0.9189
    0.7966
    0.5504
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4882
    0.5007
    0.5101

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17653
iteration: 386
epsilon =
    0.0827

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0785
    1.5257
    1.1028
    0.3139
    0.6513
    0.9189
    0.7966
    0.5504
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4882
    0.5007
    0.5101

current state : 5 next state : 1 taken action : 0  0
 next reward : 0
iteration: 387
epsilon =
    0.2453

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0785
    1.5257
    1.1028
    0.3139
    0.6513
    0.9189
    0.7966
    0.5504
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4882
    0.4871
    0.5101

current state : 1 next state : 19 taken action : 10000000   2500000
 next reward : 0.0033167
iteration: 388
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0785
    1.5257
    1.1028
    0.3139
    0.6513
    0.9189
    0.7966
    0.5504
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4879
    0.4871
    0.5101

current state : 19 next state : 18 taken action : 10000000   1000000
 next reward : 0.0033443
iteration: 389
epsilon =
    0.4249

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0785
    1.5257
    1.1028
    0.3139
    0.6513
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4879
    0.4871
    0.5101

current state : 18 next state : 12 taken action : 5000000  5000000
 next reward : 0.0057536
iteration: 390
epsilon =
    0.3359

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0785
    1.5257
    1.0912
    0.3139
    0.6513
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4879
    0.4871
    0.5101

current state : 12 next state : 7 taken action : 2500000  2500000
 next reward : 0.18713
iteration: 391
epsilon =
    0.2539

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0785
    1.5257
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4879
    0.4871
    0.5101

current state : 7 next state : 9 taken action : 5000000        0
 next reward : 0.014123
iteration: 392
epsilon =
    0.3591

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0028
    1.0785
    1.5257
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4879
    0.4871
    0.5101

current state : 9 next state : 10 taken action : 5000000  1000000
 next reward : 0.079254
iteration: 393
epsilon =
    0.4750

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0785
    1.5257
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4879
    0.4871
    0.5101

current state : 10 next state : 4 taken action : 0  5000000
 next reward : 3.2379e-15
iteration: 394
epsilon =
    0.9500

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0785
    1.5257
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4879
    0.4871
    0.5067

current state : 4 next state : 20 taken action : 10000000   5000000
 next reward : 0.0040416
iteration: 395
epsilon =
    0.2635

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0785
    1.5257
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4879
    0.4871
    0.5067

current state : 20 next state : 18 taken action : 10000000   1000000
 next reward : 0.0033433
iteration: 396
epsilon =
    0.3878

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0785
    1.5224
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4879
    0.4871
    0.5067

current state : 18 next state : 6 taken action : 2500000  1000000
 next reward : 1
iteration: 397
epsilon =
    0.3359

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0782
    1.5224
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4879
    0.4871
    0.5067

current state : 6 next state : 5 taken action : 2500000        0
 next reward : 0.17816
iteration: 398
epsilon =
    0.0824

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0778
    1.5224
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17781
iteration: 399
epsilon =
    0.0821

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0774
    1.5224
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17748
iteration: 400
epsilon =
    0.0818

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0770
    1.5224
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17714
iteration: 401
epsilon =
    0.0815

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0766
    1.5224
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17682
iteration: 402
epsilon =
    0.0812

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0762
    1.5224
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1765
iteration: 403
epsilon =
    0.0809

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0758
    1.5224
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17618
iteration: 404
epsilon =
    0.0806

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0754
    1.5224
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17587
iteration: 405
epsilon =
    0.0803

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0750
    1.5224
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17556
iteration: 406
epsilon =
    0.0800

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0746
    1.5224
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17525
iteration: 407
epsilon =
    0.0797

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0743
    1.5224
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17496
iteration: 408
epsilon =
    0.0794

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0739
    1.5224
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17466
iteration: 409
epsilon =
    0.0792

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0736
    1.5224
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17437
iteration: 410
epsilon =
    0.0789

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0732
    1.5224
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17409
iteration: 411
epsilon =
    0.0786

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0729
    1.5224
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1738
iteration: 412
epsilon =
    0.0784

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0725
    1.5224
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17353
iteration: 413
epsilon =
    0.0781

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0722
    1.5224
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17325
iteration: 414
epsilon =
    0.0778

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0718
    1.5224
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17298
iteration: 415
epsilon =
    0.0776

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0715
    1.5224
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5701
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17271
iteration: 416
epsilon =
    0.0773

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0715
    1.5224
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 16 taken action : 7500000  5000000
 next reward : 0.0068204
iteration: 417
epsilon =
    0.4750

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0715
    1.5186
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 16 next state : 6 taken action : 2500000  1000000
 next reward : 1
iteration: 418
epsilon =
    0.3167

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0713
    1.5186
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 6 next state : 5 taken action : 2500000        0
 next reward : 0.17467
iteration: 419
epsilon =
    0.0771

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0709
    1.5186
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17441
iteration: 420
epsilon =
    0.0768

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0706
    1.5186
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17415
iteration: 421
epsilon =
    0.0766

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0703
    1.5186
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1739
iteration: 422
epsilon =
    0.0763

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0700
    1.5186
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17364
iteration: 423
epsilon =
    0.0761

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0697
    1.5186
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17339
iteration: 424
epsilon =
    0.0758

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0694
    1.5186
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17315
iteration: 425
epsilon =
    0.0756

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0691
    1.5186
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17291
iteration: 426
epsilon =
    0.0753

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0688
    1.5186
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17267
iteration: 427
epsilon =
    0.0751

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0685
    1.5186
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17243
iteration: 428
epsilon =
    0.0749

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0682
    1.5186
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1722
iteration: 429
epsilon =
    0.0746

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0679
    1.5186
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17197
iteration: 430
epsilon =
    0.0744

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0676
    1.5186
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17174
iteration: 431
epsilon =
    0.0742

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0673
    1.5186
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5438
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17151
iteration: 432
epsilon =
    0.0740

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0673
    1.5186
    1.0912
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 12 taken action : 5000000  5000000
 next reward : 0.0056184
iteration: 433
epsilon =
    0.3167

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0673
    1.5186
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 12 next state : 7 taken action : 2500000  2500000
 next reward : 0.18248
iteration: 434
epsilon =
    0.2453

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0673
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 7 next state : 6 taken action : 2500000  1000000
 next reward : 1
iteration: 435
epsilon =
    0.3004

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0671
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 6 next state : 5 taken action : 2500000        0
 next reward : 0.1742
iteration: 436
epsilon =
    0.0737

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0669
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17398
iteration: 437
epsilon =
    0.0735

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0666
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17376
iteration: 438
epsilon =
    0.0733

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0663
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17354
iteration: 439
epsilon =
    0.0731

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0661
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17333
iteration: 440
epsilon =
    0.0729

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0658
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17311
iteration: 441
epsilon =
    0.0726

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0655
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1729
iteration: 442
epsilon =
    0.0724

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0653
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1727
iteration: 443
epsilon =
    0.0722

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0650
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17249
iteration: 444
epsilon =
    0.0720

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0648
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17229
iteration: 445
epsilon =
    0.0718

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0645
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17209
iteration: 446
epsilon =
    0.0716

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0643
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17189
iteration: 447
epsilon =
    0.0714

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0640
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1717
iteration: 448
epsilon =
    0.0712

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0638
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1715
iteration: 449
epsilon =
    0.0710

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0636
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17131
iteration: 450
epsilon =
    0.0708

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0633
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17112
iteration: 451
epsilon =
    0.0706

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0631
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17094
iteration: 452
epsilon =
    0.0704

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0629
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17075
iteration: 453
epsilon =
    0.0702

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0626
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17057
iteration: 454
epsilon =
    0.0700

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0624
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17039
iteration: 455
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0622
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17021
iteration: 456
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0620
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.17004
iteration: 457
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0618
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16986
iteration: 458
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0615
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16969
iteration: 459
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0613
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16952
iteration: 460
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0611
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16935
iteration: 461
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0609
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16918
iteration: 462
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0607
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16902
iteration: 463
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0605
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16885
iteration: 464
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0603
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16869
iteration: 465
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0601
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16853
iteration: 466
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0599
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16837
iteration: 467
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0597
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16822
iteration: 468
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0595
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16806
iteration: 469
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0593
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16791
iteration: 470
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0591
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16776
iteration: 471
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0589
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16761
iteration: 472
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0587
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16746
iteration: 473
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0586
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16731
iteration: 474
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0584
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16717
iteration: 475
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0582
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16702
iteration: 476
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0580
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16688
iteration: 477
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0578
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16674
iteration: 478
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0577
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1666
iteration: 479
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0575
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16646
iteration: 480
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0573
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16632
iteration: 481
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0571
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16619
iteration: 482
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0570
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16605
iteration: 483
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0568
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16592
iteration: 484
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0566
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16579
iteration: 485
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0565
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16566
iteration: 486
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0563
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16553
iteration: 487
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0561
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1654
iteration: 488
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0560
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16527
iteration: 489
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0558
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16515
iteration: 490
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0556
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16502
iteration: 491
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0555
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1649
iteration: 492
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0553
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16477
iteration: 493
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0552
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16465
iteration: 494
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0550
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16453
iteration: 495
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0549
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16441
iteration: 496
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0547
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1643
iteration: 497
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0546
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16418
iteration: 498
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0544
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16406
iteration: 499
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0543
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16395
iteration: 500
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0541
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16383
iteration: 501
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0540
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16372
iteration: 502
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0538
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16361
iteration: 503
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0537
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1635
iteration: 504
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0535
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16339
iteration: 505
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0534
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16328
iteration: 506
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0533
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16317
iteration: 507
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0531
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16307
iteration: 508
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0530
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16296
iteration: 509
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0529
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16285
iteration: 510
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0527
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16275
iteration: 511
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0526
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16265
iteration: 512
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0525
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16254
iteration: 513
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0523
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16244
iteration: 514
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0522
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16234
iteration: 515
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0521
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16224
iteration: 516
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0519
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16214
iteration: 517
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0518
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16204
iteration: 518
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0517
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16195
iteration: 519
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0516
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16185
iteration: 520
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0514
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16175
iteration: 521
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0513
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16166
iteration: 522
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0512
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16157
iteration: 523
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0511
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16147
iteration: 524
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0509
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16138
iteration: 525
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0508
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16129
iteration: 526
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0507
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1612
iteration: 527
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0506
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16111
iteration: 528
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0505
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16102
iteration: 529
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0504
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16093
iteration: 530
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0502
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16084
iteration: 531
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0501
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16075
iteration: 532
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0500
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16066
iteration: 533
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0499
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16058
iteration: 534
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0498
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16049
iteration: 535
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0497
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16041
iteration: 536
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0496
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16032
iteration: 537
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0494
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16024
iteration: 538
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0493
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16015
iteration: 539
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0492
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.16007
iteration: 540
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0491
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15999
iteration: 541
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0490
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15991
iteration: 542
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0489
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15983
iteration: 543
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0488
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15975
iteration: 544
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0487
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15967
iteration: 545
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0486
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15959
iteration: 546
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0485
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15951
iteration: 547
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0484
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15943
iteration: 548
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0483
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15936
iteration: 549
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0482
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15928
iteration: 550
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0481
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1592
iteration: 551
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0480
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15913
iteration: 552
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0479
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15905
iteration: 553
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0478
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15898
iteration: 554
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0477
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15891
iteration: 555
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0476
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15883
iteration: 556
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0475
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15876
iteration: 557
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0474
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15869
iteration: 558
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0473
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15862
iteration: 559
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0472
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15854
iteration: 560
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0471
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15847
iteration: 561
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0470
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1584
iteration: 562
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0469
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15833
iteration: 563
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0469
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15826
iteration: 564
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0468
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1582
iteration: 565
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0467
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15813
iteration: 566
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0466
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15806
iteration: 567
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0465
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15799
iteration: 568
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0464
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15793
iteration: 569
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0463
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15786
iteration: 570
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0462
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15779
iteration: 571
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0461
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15773
iteration: 572
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0461
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15766
iteration: 573
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0460
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1576
iteration: 574
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0459
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15753
iteration: 575
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0458
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15747
iteration: 576
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0457
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15741
iteration: 577
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0456
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15734
iteration: 578
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0455
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15728
iteration: 579
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0455
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15722
iteration: 580
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0454
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15716
iteration: 581
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0453
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1571
iteration: 582
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0452
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15703
iteration: 583
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0451
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15697
iteration: 584
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0451
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15691
iteration: 585
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0450
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15685
iteration: 586
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0449
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15679
iteration: 587
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0448
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15674
iteration: 588
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0447
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15668
iteration: 589
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0447
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15662
iteration: 590
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0446
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15656
iteration: 591
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0445
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1565
iteration: 592
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0444
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15645
iteration: 593
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0444
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15639
iteration: 594
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0443
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15633
iteration: 595
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0442
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15628
iteration: 596
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0441
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15622
iteration: 597
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0441
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15617
iteration: 598
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0440
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15611
iteration: 599
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0439
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15606
iteration: 600
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0438
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.156
iteration: 601
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0438
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15595
iteration: 602
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0437
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.1559
iteration: 603
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0436
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15584
iteration: 604
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0436
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15579
iteration: 605
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0435
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15574
iteration: 606
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0434
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15568
iteration: 607
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0433
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15563
iteration: 608
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0433
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15558
iteration: 609
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0432
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15553
iteration: 610
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0431
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15548
iteration: 611
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0431
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15543
iteration: 612
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0430
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15538
iteration: 613
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0429
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15533
iteration: 614
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0429
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15528
iteration: 615
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0428
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15523
iteration: 616
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0427
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15518
iteration: 617
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0427
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15513
iteration: 618
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0426
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15508
iteration: 619
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0425
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15503
iteration: 620
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0425
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15498
iteration: 621
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0424
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15494
iteration: 622
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0423
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15489
iteration: 623
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0423
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15484
iteration: 624
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0422
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15479
iteration: 625
epsilon =
     0

MeanR =
   1.0e+04 *

         0
    0.0328
   -0.0238
    0.0019
    1.0422
    1.5136
    1.0807
    0.3139
    0.6508
    0.9189
    0.7966
    0.5387
    0.4386
    0.6083
    0.6454
    0.5614
    0.2903
    0.4879
    0.4871
    0.5067

current state : 5 next state : 5 taken action : 2500000        0
 next reward : 0.15475
iteration: 626
epsilon =
     0

Elapsed time is 1007.940693 seconds.

Post-processing and saving...   
Elapsed time is 4.283198 seconds.
